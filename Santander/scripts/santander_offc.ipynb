{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "# length of dataset\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImputeFrequent values to -9999999 to most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values=-999999,strategy=\"most_frequent\",axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = imp.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = imp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in X_train if len(set(x))==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Min Max Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#split_in_2_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Standard_scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "#####################################\n",
    "X_train_ss = ss.fit_transform(X_train)\n",
    "X_test_ss = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name FunctionTransformer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-734c282fcd19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#log(1+X) Transformation#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlog1p_trans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog1p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog1p_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog1p_trans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name FunctionTransformer"
     ]
    }
   ],
   "source": [
    "# 2. log(1+X) Transformation and SS#\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "log1p_trans = FunctionTransformer(np.log1p)\n",
    "X_train_log1p = log1p_trans.transform(X_train)\n",
    "X_test_log1p = log1p_trans.transform(X_test)\n",
    "ss = StandardScaler()\n",
    "#############################################\n",
    "X_train_log = ss.fit_transform(X_train_log1p)\n",
    "X_test_log = ss.transform(X_test_log1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a CV SET for stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cv data will be used for tuning 2nd level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train_ss_stacker, X_cv_ss_stacker, y_train_ss_stacker, y_cv_ss_stacker = train_test_split(X_train_ss, y_train, test_size=0.2, \n",
    "# stratify = y_train,random_state=42)\n",
    "X_train_ss_stacker, X_cv_ss_stacker, y_train_ss_stacker, y_cv_ss_stacker = \n",
    "train_test_split(X_train_ss, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#now treat X_train_ss_stacker as training and X_cv_ss_stacker as x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_ss_stacker will have 4fold cv and will create blend_test also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=15, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=6, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=366, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classifier\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "#Best CV Scores\n",
    "#num_trees:366,max_depth:15,max_features:auto,min_samples_split:2,min_samples_leaf:6,criterion:entropy,mean:0.837152757842,std:0.0087282640641\n",
    "\n",
    "clfrf = RandomForestClassifier(n_estimators=366,max_depth=15,max_features='auto',min_samples_split=2,\n",
    "                             min_samples_leaf=6,criterion='entropy')\n",
    "\n",
    "clfrf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.03, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=10, min_samples_split=3,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=785,\n",
       "              random_state=None, subsample=0.85, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting\n",
    "# GBT:learning_rate:0.03,n_estimators:785,subsample:0.85,min_samples_split:3,min_samples_leaf:10,min_weight_fraction_leaf:0,max_depth:3,mean:0.837373013071,std:0.00851364001698\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfgbt = GradientBoostingClassifier(learning_rate=.03,n_estimators=785,\n",
    "                                          subsample=0.85,min_samples_split=3,\n",
    "                                          min_samples_leaf=10,max_depth=3)\n",
    "\n",
    "clfgbt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "#print('Overall AUC:', roc_auc_score(y_train, clf.predict_proba(X_train)[:,1]))\n",
    "\n",
    "# predicting\n",
    "y_pred_rf= clfrf.predict_proba(X_test)[:,1]\n",
    "y_pred_gbt= clfgbt.predict_proba(X_test)[:,1]\n",
    "xgb_res = pd.read_csv('submission_kagglr.csv')\n",
    "y_pred_xgb = xgb_res['TARGET']\n",
    "\n",
    "# cREATING DATA BY ENSEMBLING\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"RF\":y_pred_rf,\"XGB\":y_pred_xgb,\"GBT\":y_pred_gbt})\n",
    "submission['TARGET'] = .60*submission['XGB']+.10*submission['GBT']+.30*submission['RF']\n",
    "submission = submission[['ID','TARGET']]\n",
    "\n",
    "submission.to_csv(\"submission_ENS2.csv\", index=False)\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.044794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.053102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.002526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.015318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.003319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    TARGET\n",
       "0   2  0.044794\n",
       "1   5  0.053102\n",
       "2   6  0.002526\n",
       "3   7  0.015318\n",
       "4   9  0.003319"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "class stacker(object):\n",
    "    def __init__(self , x_test , x_train , y_train,  base_clf_list=[], blender_clf_list = [], \n",
    "                 random_seed = 0,n_folds = 5, eval_metric='roc_auc'):\n",
    "        \"\"\" initializes a stacker object \"\"\"\n",
    "        self.__base_clf_list = base_clf_list\n",
    "        self.__blender_clf_list = blender_clf_list\n",
    "        self.__random_seed     = random_seed\n",
    "        self.__n_folds = n_folds\n",
    "        self.__X_test = x_test\n",
    "        self.__X = x_train\n",
    "        self.__y = y_train\n",
    "        # Number of training data x Number of classifiers\n",
    "        self.__blend_train = np.zeros((self.__X.shape[0], len(self.__base_clf_list))) \n",
    "         # Number of testing data x Number of classifiers\n",
    "        self.__blend_test = np.zeros((self.__X_test.shape[0], len(self.__base_clf_list)))\n",
    "        self.__eval_metric=eval_metric\n",
    "        self.__clf_fold_auc = {}\n",
    "        self.__blender_fold_auc = {}\n",
    "        self.__skf = list(StratifiedKFold(self.__y, self.__n_folds,shuffle=True,random_state=self.__random_seed))\n",
    "        self.__blender_preds = np.zeros((self.__X_test.shape[0], len(self.__blender_clf_list)))\n",
    "        self.__id_test = id_test\n",
    "\n",
    "    def train_all_base_classifiers(self):\n",
    "        \"\"\" trains the Blender creates a blended_test and blended_train df\"\"\"\n",
    "        skf = self.__skf\n",
    "         # For each classifier, we train the number of fold times (=len(skf))\n",
    "        for j, clf in enumerate(self.__base_clf_list):\n",
    "            print 'Training classifier [%s] [%s]' % (j,clf[1])\n",
    "            # Number of testing data x Number of folds , we will take the mean of the predictions later\n",
    "            blend_test_j = np.zeros((self.__X_test.shape[0], len(skf))) \n",
    "            for i, (train_index, cv_index) in enumerate(skf):\n",
    "                print 'Fold [%s]' % (i)\n",
    "                # This is the training and validation set\n",
    "                X_tr = self.__X[train_index]\n",
    "                Y_tr = self.__y[train_index]\n",
    "                X_cv = self.__X[cv_index]\n",
    "                Y_cv = self.__y[cv_index]\n",
    "                clf[0].fit(X_tr, Y_tr)\n",
    "                class_preds = clf[0].predict_proba(X_cv)[:,1]\n",
    "                eval_metric = self.__eval_metric\n",
    "                auc_score = roc_auc_score(Y_cv, class_preds)\n",
    "                print \"auc_score for fold:\",auc_score\n",
    "                if clf[1] in self.__clf_fold_auc:\n",
    "                    self.__clf_fold_auc[clf[1]].append(auc_score)\n",
    "                else:\n",
    "                    self.__clf_fold_auc[clf[1]] = [auc_score]\n",
    "                # This output will be the basis for our blended classifier to train against,\n",
    "                # which is also the output of our classifiers\n",
    "                self.__blend_train[cv_index, j] = class_preds\n",
    "                blend_test_j[:, i] = clf[0].predict_proba(self.__X_test)[:,1]\n",
    "            # Take the mean of the predictions of the cross validation set\n",
    "            print \"cv_score_mean:\",np.mean(self.__clf_fold_auc[clf[1]]),\"and cv_score_std:\",np.std(self.__clf_fold_auc[clf[1]])\n",
    "            self.__blend_test[:, j] = blend_test_j.mean(1)\n",
    "\n",
    "    def add_base_classifer(self,clf):\n",
    "        self.__base_clf_list.append(clf)\n",
    "        # add a new column to both blended train and test\n",
    "        self.__blend_train = np.c_[self.__blend_train,np.zeros(self.__X.shape[0])]\n",
    "        self.__blend_test = np.c_[self.__blend_test,np.zeros(self.__X_test.shape[0])]\n",
    "        print 'Training classifier [%s] [%s]' % (len(self.__base_clf_list),clf[1])\n",
    "        # Number of testing data x Number of folds , we will take the mean of the predictions later\n",
    "        blend_test_j = np.zeros((self.__X_test.shape[0], len(self.__skf))) \n",
    "        for i, (train_index, cv_index) in enumerate(self.__skf):\n",
    "            print 'Fold [%s]' % (i)\n",
    "            # This is the training and validation set\n",
    "            X_tr = self.__X[train_index]\n",
    "            Y_tr = self.__y[train_index]\n",
    "            X_cv = self.__X[cv_index]\n",
    "            Y_cv = self.__y[cv_index]\n",
    "            clf[0].fit(X_tr, Y_tr)\n",
    "            class_preds = clf[0].predict_proba(X_cv)[:,1]\n",
    "            eval_metric = self.__eval_metric\n",
    "            auc_score = roc_auc_score(Y_cv, class_preds)\n",
    "            print \"auc_score for fold:\",auc_score\n",
    "            if clf[1] in self.__clf_fold_auc:\n",
    "                self.__clf_fold_auc[clf[1]].append(auc_score)\n",
    "            else:\n",
    "                self.__clf_fold_auc[clf[1]] = [auc_score]\n",
    "            # This output will be the basis for our blended classifier to train against,\n",
    "            # which is also the output of our classifiers\n",
    "            self.__blend_train[cv_index, len(self.__base_clf_list)-1] = class_preds\n",
    "            blend_test_j[:, i] = clf[0].predict_proba(self.__X_test)[:,1]\n",
    "        # Take the mean of the predictions of the cross validation set\n",
    "        print \"cv_score_mean:\",np.mean(self.__clf_fold_auc[clf[1]]),\"and cv_score_std:\",np.std(self.__clf_fold_auc[clf[1]])\n",
    "        self.__blend_test[:, len(self.__base_clf_list)-1] = blend_test_j.mean(1)\n",
    "    \n",
    "    def add_blenders(self,blender):\n",
    "        self.__blender_clf_list.append(blender)\n",
    "\n",
    "    def remove_blenders(self,blender):\n",
    "        self.__blender_clf_list.remove(blender)\n",
    "    \n",
    "    def find_cv_scores_all_blenders(self):\n",
    "        for blender,blendername in self.__blender_clf_list:\n",
    "            print \"blender_Name:\",blendername,\":\"\n",
    "            for i, (train_index, cv_index) in enumerate(self.__skf):\n",
    "                X_tr = self.__blend_train[train_index]\n",
    "                Y_tr = self.__y[train_index]\n",
    "                X_cv = self.__blend_train[cv_index]\n",
    "                Y_cv = self.__y[cv_index]\n",
    "                blender.fit(X_tr, Y_tr)\n",
    "                class_preds = blender.predict_proba(X_cv)[:,1]\n",
    "                auc_score = roc_auc_score(Y_cv, class_preds)\n",
    "                print \"Fold\",i+1,\"CV Score:\",auc_score\n",
    "                if blendername in self.__blender_fold_auc:\n",
    "                    self.__blender_fold_auc[blendername].append(auc_score)\n",
    "                else:\n",
    "                    self.__blender_fold_auc[blendername] = [auc_score]\n",
    "            print \"cv_score_mean:\",np.mean(self.__blender_fold_auc[blendername]),\"and cv_score_std:\",np.std(self.__blender_fold_auc[blendername])\n",
    "        \n",
    "    def train_all_blenders(self):\n",
    "        self.__blender_preds = np.zeros((self.__X_test.shape[0], len(self.__blender_clf_list)))\n",
    "        for i,blender_obj in enumerate(self.__blender_clf_list):\n",
    "            blender,blender_name = blender_obj\n",
    "            print \"Training Blender #\",i+1,\"|\",blender_name\n",
    "            blender.fit(self.__blend_train,self.__y)\n",
    "            blender_probs = blender.predict_proba(self.__blend_test)[:,1]\n",
    "            self.__blender_preds[:, i] = blender_probs\n",
    "\n",
    "    def get_weighted_blender_submission(self,submission_name,req_blender_list=[], blender_weights=0):\n",
    "        \"\"\"blender_weights should be a np.array\"\"\"\n",
    "        if len(req_blender_list)==0:\n",
    "            req_blender_list = [x[1] for x in self.__blender_clf_list]\n",
    "        blender_dataframe = pd.DataFrame(self.__blender_preds,columns= [x[1] for x in self.__blender_clf_list])\n",
    "        if blender_weights==0:\n",
    "            #print blender_dataframe\n",
    "            #print req_blender_list\n",
    "            blender_df = blender_dataframe[req_blender_list]\n",
    "            \n",
    "            new_blender_array = np.sum(np.array(blender_df),axis=1)/len(req_blender_list)\n",
    "        else:\n",
    "            blender_weights = np.array(blender_weights)\n",
    "            blender_df = blender_dataframe[req_blender_list]\n",
    "            new_blender_array =np.dot(np.array(blender_df),blender_weights)\n",
    "        submission = pd.DataFrame({\"ID\":self.__id_test, \"TARGET\":new_blender_array})\n",
    "        submission.to_csv(submission_name, index=False)\n",
    "        return submission\n",
    "\n",
    "    ### ADD YOU OWN GETTER SETTER FUNCS.\n",
    "    def get_blend_train(self):\n",
    "        return self.__blend_train\n",
    "\n",
    "    def get_blend_test(self):\n",
    "        return self.__blend_test\n",
    "\n",
    "    def get_blended_preds_df(self):\n",
    "        return pd.DataFrame(self.__blender_preds,columns= [x[1] for x in self.__blender_clf_list])\n",
    "\n",
    "    def __str__(self):\n",
    "        res = \"init:\\n\" + \"n_folds: \" + str(self.__n_folds) +\" random_seed:\"+str(self.__random_seed)+\"\\n\"\n",
    "        res += \"base classifiers:\\n\"\n",
    "        for clf_num,clf in enumerate(self.__base_clf_list):\n",
    "            res += str(clf_num+1)+\". \"+str(clf) + \" \\n\"\n",
    "            for i, auc_score in enumerate(self.__clf_fold_auc[clf[1]]):\n",
    "                res += \"fold_\"+str(i+1)+\"_auc:\"+str(auc_score)+\"\\n\"\n",
    "\n",
    "        res += \"Blender classifiers:\\n\"\n",
    "        for clf_num,clf in enumerate(self.__blender_clf_list):\n",
    "            res += str(clf_num+1)+\". \"+str(clf) + \" \\n\"\n",
    "            for i, auc_score in enumerate(self.__blender_fold_auc[clf[1]]):\n",
    "                res += \"fold_\"+str(i+1)+\"_auc:\"+str(auc_score)+\"\\n\"\n",
    "        \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack2 = stacker(x_test = X_cv_ss_stacker,x_train = X_train_ss_stacker,y_train =y_train_ss_stacker)\n",
    "#X_train_ss_stacker, X_cv_ss_stacker, y_train_ss_stacker, y_cv_ss_stacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [1] [RF_GINI]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.685457288813\n",
      "Fold [1]\n",
      "auc_score for fold: 0.674064702274\n",
      "Fold [2]\n",
      "auc_score for fold: 0.66895756655\n",
      "Fold [3]\n",
      "auc_score for fold: 0.673893067563\n",
      "Fold [4]\n",
      "auc_score for fold: 0.697194017661\n",
      "cv_score_mean: 0.679913328572 and cv_score_std: 0.0101964347124\n"
     ]
    }
   ],
   "source": [
    "stack2.add_base_classifer([RandomForestClassifier(n_estimators = 10, criterion = 'gini'),\"RF_GINI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [2] [RF_ENTROPY]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.690217835215\n",
      "Fold [1]\n",
      "auc_score for fold: 0.674254704129\n",
      "Fold [2]\n",
      "auc_score for fold: 0.665954806129\n",
      "Fold [3]\n",
      "auc_score for fold: 0.690976650546\n",
      "Fold [4]\n",
      "auc_score for fold: 0.694794876459\n",
      "cv_score_mean: 0.683239774495 and cv_score_std: 0.0111496599478\n"
     ]
    }
   ],
   "source": [
    "stack2.add_base_classifer([RandomForestClassifier(n_estimators = 10, criterion = 'entropy'),\"RF_ENTROPY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [3] [GB]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.81978621673\n",
      "Fold [1]\n",
      "auc_score for fold: 0.800097542013\n",
      "Fold [2]\n",
      "auc_score for fold: 0.804099974322\n",
      "Fold [3]\n",
      "auc_score for fold: 0.823448243887\n",
      "Fold [4]\n",
      "auc_score for fold: 0.829046834432\n",
      "cv_score_mean: 0.815295762277 and cv_score_std: 0.0112432263177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "stack2.add_base_classifer([GradientBoostingClassifier(n_estimators=10),\"GB\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_cv = stack2.get_blend_test()\n",
    "x_tr = stack2.get_blend_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "blender = LogisticRegression()\n",
    "blender.fit(x_tr,y_train_ss_stacker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc:train 0.818490102433\n",
      "local_cv_error:test 0.824884917451\n"
     ]
    }
   ],
   "source": [
    "print \"auc:train\",roc_auc_score(y_train_ss_stacker,blender.predict_proba(x_tr)[:,1])\n",
    "print \"local_cv_error:test\",roc_auc_score(y_cv_ss_stacker,blender.predict_proba(x_cv)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-1cf3da5a1452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mblender\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "blender.predict(x_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack3 = stacker(x_test = X_test,x_train = X_train,y_train =y_train,id_test=id_test, base_clf_list=[[RandomForestClassifier(n_estimators = 2, criterion = 'entropy'),\"RF_ENTROPY\"],\n",
    "                                                                                   [RandomForestClassifier(n_estimators = 2, criterion = 'gini'),\"RF_GINI\"]\n",
    "                                                                                   ]\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0] [RF_ENTROPY]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.587837444315\n",
      "Fold [1]\n",
      "auc_score for fold: 0.586507960522\n",
      "Fold [2]\n",
      "auc_score for fold: 0.585919316109\n",
      "Fold [3]\n",
      "auc_score for fold: 0.597974521303\n",
      "Fold [4]\n",
      "auc_score for fold: 0.58788051508\n",
      "cv_score_mean: 0.589223951466 and cv_score_std: 0.00444065124784\n",
      "Training classifier [1] [RF_GINI]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.595458187607\n",
      "Fold [1]\n",
      "auc_score for fold: 0.597067218473\n",
      "Fold [2]\n",
      "auc_score for fold: 0.58707318799\n",
      "Fold [3]\n",
      "auc_score for fold: 0.60299280909\n",
      "Fold [4]\n",
      "auc_score for fold: 0.593728641553\n",
      "cv_score_mean: 0.595264008943 and cv_score_std: 0.00514724241871\n"
     ]
    }
   ],
   "source": [
    "stack3.train_all_base_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack4 = stacker(x_test = X_test,x_train = X_train,y_train =y_train,id_test=id_test, base_clf_list=[[RandomForestClassifier(n_estimators = 2, criterion = 'entropy'),\"RF_ENTROPY\"],\n",
    "                                                                                   [RandomForestClassifier(n_estimators = 2, criterion = 'gini'),\"RF_GINI\"]\n",
    "                                                                                   ],\n",
    "                 \n",
    "                 blender_clf_list = [[RandomForestClassifier(n_estimators = 2, criterion = 'entropy'),\"BLEND_RF_ENTROPY\"],\n",
    "                                                                                   [RandomForestClassifier(n_estimators = 2, criterion = 'gini'),\"BLEND_RF_GINI\"]\n",
    "                                                                                   ]\n",
    "                ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier [0] [RF_ENTROPY]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.601556465779\n",
      "Fold [1]\n",
      "auc_score for fold: 0.604232041248\n",
      "Fold [2]\n",
      "auc_score for fold: 0.584394983439\n",
      "Fold [3]\n",
      "auc_score for fold: 0.603993230476\n",
      "Fold [4]\n",
      "auc_score for fold: 0.59159561713\n",
      "cv_score_mean: 0.597154467614 and cv_score_std: 0.00787329116686\n",
      "Training classifier [1] [RF_GINI]\n",
      "Fold [0]\n",
      "auc_score for fold: 0.590317422147\n",
      "Fold [1]\n",
      "auc_score for fold: 0.604126251307\n",
      "Fold [2]\n",
      "auc_score for fold: 0.598296676694\n",
      "Fold [3]\n",
      "auc_score for fold: 0.593156671037\n",
      "Fold [4]\n",
      "auc_score for fold: 0.579752596971\n",
      "cv_score_mean: 0.593129923631 and cv_score_std: 0.00817897680863\n"
     ]
    }
   ],
   "source": [
    "stack4.train_all_base_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Blender # 1 | BLEND_RF_ENTROPY\n",
      "Training Blender # 2 | BLEND_RF_GINI\n"
     ]
    }
   ],
   "source": [
    "stack4.train_all_blenders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blender_Name: BLEND_RF_ENTROPY :\n",
      "Fold 1 CV Score: 0.602361151841\n",
      "Fold 2 CV Score: 0.625628341057\n",
      "Fold 3 CV Score: 0.596159573553\n",
      "Fold 4 CV Score: 0.601513229218\n",
      "Fold 5 CV Score: 0.596663814886\n",
      "cv_score_mean: 0.604465222111 and cv_score_std: 0.0108707380607\n",
      "blender_Name: BLEND_RF_GINI :\n",
      "Fold 1 CV Score: 0.597490833245\n",
      "Fold 2 CV Score: 0.614910113814\n",
      "Fold 3 CV Score: 0.595923008772\n",
      "Fold 4 CV Score: 0.604254460162\n",
      "Fold 5 CV Score: 0.591763066213\n",
      "cv_score_mean: 0.600868296441 and cv_score_std: 0.00809205888706\n"
     ]
    }
   ],
   "source": [
    "stack4.find_cv_scores_all_blenders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init:\n",
      "n_folds: 5 random_seed:0\n",
      "base classifiers:\n",
      "1. [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'RF_ENTROPY'] \n",
      "fold_1_auc:0.601556465779\n",
      "fold_2_auc:0.604232041248\n",
      "fold_3_auc:0.584394983439\n",
      "fold_4_auc:0.603993230476\n",
      "fold_5_auc:0.59159561713\n",
      "2. [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'RF_GINI'] \n",
      "fold_1_auc:0.590317422147\n",
      "fold_2_auc:0.604126251307\n",
      "fold_3_auc:0.598296676694\n",
      "fold_4_auc:0.593156671037\n",
      "fold_5_auc:0.579752596971\n",
      "Blender classifiers:\n",
      "1. [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'BLEND_RF_ENTROPY'] \n",
      "fold_1_auc:0.602361151841\n",
      "fold_2_auc:0.625628341057\n",
      "fold_3_auc:0.596159573553\n",
      "fold_4_auc:0.601513229218\n",
      "fold_5_auc:0.596663814886\n",
      "2. [RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=2, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False), 'BLEND_RF_GINI'] \n",
      "fold_1_auc:0.597490833245\n",
      "fold_2_auc:0.614910113814\n",
      "fold_3_auc:0.595923008772\n",
      "fold_4_auc:0.604254460162\n",
      "fold_5_auc:0.591763066213\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(stack4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       BLEND_RF_ENTROPY  BLEND_RF_GINI\n",
      "0              0.000000       0.000000\n",
      "1              0.028725       0.028071\n",
      "2              0.028725       0.028071\n",
      "3              0.028725       0.028071\n",
      "4              0.028725       0.028071\n",
      "5              0.000000       0.000000\n",
      "6              0.000000       0.000000\n",
      "7              0.028725       0.028071\n",
      "8              0.000000       0.000000\n",
      "9              0.000000       0.000000\n",
      "10             0.028725       0.028071\n",
      "11             0.028725       0.028071\n",
      "12             0.028725       0.028071\n",
      "13             0.028725       0.028071\n",
      "14             0.028725       0.028071\n",
      "15             0.000000       0.000000\n",
      "16             0.000000       0.000000\n",
      "17             0.028725       0.028071\n",
      "18             0.028725       0.028071\n",
      "19             0.000000       0.000000\n",
      "20             0.028725       0.028071\n",
      "21             0.166667       0.000000\n",
      "22             0.028725       0.028071\n",
      "23             0.028725       0.028071\n",
      "24             0.000000       0.000000\n",
      "25             0.028725       0.028071\n",
      "26             0.028725       0.028071\n",
      "27             0.028725       0.028071\n",
      "28             0.125000       0.300000\n",
      "29             0.028725       0.028071\n",
      "...                 ...            ...\n",
      "75788          0.028725       0.028071\n",
      "75789          0.000000       0.000000\n",
      "75790          0.028725       0.028071\n",
      "75791          0.028725       0.028071\n",
      "75792          0.028725       0.028071\n",
      "75793          0.028725       0.028071\n",
      "75794          0.350000       0.083333\n",
      "75795          0.500000       0.000000\n",
      "75796          0.028725       0.028071\n",
      "75797          0.350000       0.083333\n",
      "75798          0.028725       0.028071\n",
      "75799          0.028725       0.028071\n",
      "75800          0.028725       0.028071\n",
      "75801          0.028725       0.028071\n",
      "75802          0.000000       0.000000\n",
      "75803          0.028725       0.028071\n",
      "75804          0.028725       0.028071\n",
      "75805          0.028725       0.028071\n",
      "75806          0.000000       0.000000\n",
      "75807          0.028725       0.028071\n",
      "75808          0.000000       0.000000\n",
      "75809          0.000000       0.000000\n",
      "75810          0.350000       0.083333\n",
      "75811          0.028725       0.028071\n",
      "75812          0.028725       0.028071\n",
      "75813          0.500000       0.000000\n",
      "75814          0.000000       0.000000\n",
      "75815          0.028725       0.028071\n",
      "75816          0.000000       0.000000\n",
      "75817          0.028725       0.028071\n",
      "\n",
      "[75818 rows x 2 columns]\n",
      "['BLEND_RF_ENTROPY', 'BLEND_RF_GINI']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>19</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>22</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>35</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>37</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>40</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>41</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>46</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>47</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>48</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>50</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>52</td>\n",
       "      <td>0.212500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>53</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75788</th>\n",
       "      <td>151772</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75789</th>\n",
       "      <td>151773</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75790</th>\n",
       "      <td>151776</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75791</th>\n",
       "      <td>151777</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75792</th>\n",
       "      <td>151780</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75793</th>\n",
       "      <td>151781</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75794</th>\n",
       "      <td>151782</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75795</th>\n",
       "      <td>151784</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75796</th>\n",
       "      <td>151785</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75797</th>\n",
       "      <td>151786</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75798</th>\n",
       "      <td>151788</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75799</th>\n",
       "      <td>151789</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75800</th>\n",
       "      <td>151790</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75801</th>\n",
       "      <td>151791</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75802</th>\n",
       "      <td>151803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75803</th>\n",
       "      <td>151812</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75804</th>\n",
       "      <td>151814</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75805</th>\n",
       "      <td>151817</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75806</th>\n",
       "      <td>151819</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75807</th>\n",
       "      <td>151822</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75808</th>\n",
       "      <td>151823</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75809</th>\n",
       "      <td>151824</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75810</th>\n",
       "      <td>151826</td>\n",
       "      <td>0.216667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75811</th>\n",
       "      <td>151827</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75812</th>\n",
       "      <td>151828</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>151831</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>151832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>151833</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75816</th>\n",
       "      <td>151834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75817</th>\n",
       "      <td>151837</td>\n",
       "      <td>0.028398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75818 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID    TARGET\n",
       "0           2  0.000000\n",
       "1           5  0.028398\n",
       "2           6  0.028398\n",
       "3           7  0.028398\n",
       "4           9  0.028398\n",
       "5          11  0.000000\n",
       "6          12  0.000000\n",
       "7          15  0.028398\n",
       "8          16  0.000000\n",
       "9          17  0.000000\n",
       "10         19  0.028398\n",
       "11         21  0.028398\n",
       "12         22  0.028398\n",
       "13         24  0.028398\n",
       "14         27  0.028398\n",
       "15         28  0.000000\n",
       "16         30  0.000000\n",
       "17         33  0.028398\n",
       "18         35  0.028398\n",
       "19         37  0.000000\n",
       "20         38  0.028398\n",
       "21         40  0.083333\n",
       "22         41  0.028398\n",
       "23         44  0.028398\n",
       "24         46  0.000000\n",
       "25         47  0.028398\n",
       "26         48  0.028398\n",
       "27         50  0.028398\n",
       "28         52  0.212500\n",
       "29         53  0.028398\n",
       "...       ...       ...\n",
       "75788  151772  0.028398\n",
       "75789  151773  0.000000\n",
       "75790  151776  0.028398\n",
       "75791  151777  0.028398\n",
       "75792  151780  0.028398\n",
       "75793  151781  0.028398\n",
       "75794  151782  0.216667\n",
       "75795  151784  0.250000\n",
       "75796  151785  0.028398\n",
       "75797  151786  0.216667\n",
       "75798  151788  0.028398\n",
       "75799  151789  0.028398\n",
       "75800  151790  0.028398\n",
       "75801  151791  0.028398\n",
       "75802  151803  0.000000\n",
       "75803  151812  0.028398\n",
       "75804  151814  0.028398\n",
       "75805  151817  0.028398\n",
       "75806  151819  0.000000\n",
       "75807  151822  0.028398\n",
       "75808  151823  0.000000\n",
       "75809  151824  0.000000\n",
       "75810  151826  0.216667\n",
       "75811  151827  0.028398\n",
       "75812  151828  0.028398\n",
       "75813  151831  0.250000\n",
       "75814  151832  0.000000\n",
       "75815  151833  0.028398\n",
       "75816  151834  0.000000\n",
       "75817  151837  0.028398\n",
       "\n",
       "[75818 rows x 2 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack4.get_weighted_blender_submission(submission_name= \"unw_ble.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3L"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_d = pickle.load(open(\"BASE_KNN4blend_train.pkl\",\"rb\"))\n",
    "test_d = pickle.load(open(\"BASE_KNN4blend_test.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.001, loss='deviance',\n",
       "              max_depth=2, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=9, min_samples_split=9,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=4650,\n",
       "              random_state=None, subsample=0.8, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfgbt = GradientBoostingClassifier(learning_rate=0.001,n_estimators=4650,\n",
    "                                          subsample=0.8,min_samples_split=9,\n",
    "                                          min_samples_leaf=9,max_depth=2)\n",
    "\n",
    "#predsGBT:learning_rate:0.005,n_estimators:551,subsample:0.95,min_samples_split:10,min_samples_leaf:4,min_weight_fraction_leaf:0,max_depth:3,mean:0.844772435022,std:0.00374481377244\n",
    "#preds2GBT:learning_rate:0.001,n_estimators:4650,subsample:0.8,min_samples_split:8,min_samples_leaf:9,min_weight_fraction_leaf:0,max_depth:2,mean:0.845286774382,std:0.00311551434064\n",
    "\n",
    "clfgbt.fit(train_d,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds2 = clfgbt.predict_proba(test_d)[:,1]\n",
    "preds3 = (.3*preds+.7*preds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":preds3})\n",
    "submission.to_csv(\"gbt_enstrain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03228861,  0.04665701,  0.0064141 , ...,  0.0064141 ,\n",
       "        0.0478516 ,  0.0064141 ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0322188 ,  0.04812189,  0.00655761, ...,  0.00655761,\n",
       "        0.04806651,  0.00655761])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03205592,  0.05153992,  0.00689245, ...,  0.00689245,\n",
       "        0.04856795,  0.00689245])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.8407713 ,  0.8352808 ,  0.84565926,  0.85855088,  0.84116289])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "cross_val_score(clfgbt, train_d, y_train, scoring='roc_auc', cv=5, n_jobs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([ 0.8407713 ,  0.8352808 ,  0.84565926,  0.85855088,  0.84116289])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.84428502599999999, 0.0078558665836522424)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a), np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfgbt = GradientBoostingClassifier(learning_rate=.1,n_estimators=100,\n",
    "                                          subsample=0.85,min_samples_split=3,\n",
    "                                          min_samples_leaf=10,max_depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = cross_val_score(clfgbt, train_d, y_train, scoring='roc_auc', cv=5, n_jobs=2, verbose=1)\n",
    "np.mean(a), np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_blend=np.c_[train_d,y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_blend=pd.DataFrame(df_train_blend,columns=['rf','gbt','xgb','rf_bal','nn_ada','nn_sgd','knn_2','knn_4','target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_blend.to_csv(\"train_blend.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.15141854,  0.08890051,  0.26170776,  0.07933218,  0.39268729,\n",
       "        0.02268647,  0.00271389,  0.00055338])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfgbt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from patsy import dmatrices, dmatrix, demo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_blend['target'] = df_train_blend['target'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf        float64\n",
       "gbt       float64\n",
       "xgb       float64\n",
       "rf_bal    float64\n",
       "nn_ada    float64\n",
       "nn_sgd    float64\n",
       "knn_2     float64\n",
       "knn_4     float64\n",
       "target      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_blend.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install patsy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For numerical factors, num_columns must be an int",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-15456d398181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdmatrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"target ~ rf*gbt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train_blend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\patsy\\highlevel.pyc\u001b[0m in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    295\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[1;32m--> 297\u001b[1;33m                                       NA_action, return_type)\n\u001b[0m\u001b[0;32m    298\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model is missing required outcome variables\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\patsy\\highlevel.pyc\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[1;32m--> 152\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[1;32mC:\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\patsy\\highlevel.pyc\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[1;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m     55\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m                                       NA_action)\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\patsy\\build.pyc\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[1;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[0;32m    704\u001b[0m                             \u001b[0mfactor_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                             \u001b[0mnum_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_column_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m                             categories=None)\n\u001b[0m\u001b[0;32m    707\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mfactor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_levels_contrasts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WinPython-64bit-2.7.10.2\\python-2.7.10.amd64\\lib\\site-packages\\patsy\\design_info.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, factor, type, state, num_columns, categories)\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"numerical\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 raise ValueError(\"For numerical factors, num_columns \"\n\u001b[0m\u001b[0;32m     89\u001b[0m                                  \"must be an int\")\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For numerical factors, num_columns must be an int"
     ]
    }
   ],
   "source": [
    "dmatrices(\"target ~ rf*gbt\", df_train_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
