{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "# Input data files are available in the \"../data/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../data\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "# load data\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1).values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1).values\n",
    "\n",
    "# length of dataset\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good XGBoost Function From Blog Analytics Vidhya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50, show_progress=True):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=show_progress)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print cvresult\n",
    "    #Fit the algorithm on the data\n",
    "    ###alg.fit(X_train, y_train,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    ###dtrain_predictions = alg.predict(X_train)\n",
    "    ###dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    ###print \"\\nModel Report\"\n",
    "    ###print \"Accuracy : %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    ###print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start With some params and tune n_estimators first of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=(len(y_train)-sum(y_train))/sum(y_train),\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "[0]\tcv-test-auc:0.7889444+0.0347440533536\tcv-train-auc:0.8015272+0.0279617965045\n",
      "[1]\tcv-test-auc:0.8126236+0.00975955848592\tcv-train-auc:0.8310436+0.00203585250939\n",
      "[2]\tcv-test-auc:0.8161628+0.00540042233163\tcv-train-auc:0.8345774+0.00851164321621\n",
      "[3]\tcv-test-auc:0.821051+0.00857446299193\tcv-train-auc:0.839839+0.00757509543174\n",
      "[4]\tcv-test-auc:0.8265596+0.00702946992596\tcv-train-auc:0.84461+0.00398633199822\n",
      "[5]\tcv-test-auc:0.829013+0.00750894328118\tcv-train-auc:0.8467768+0.00187871726452\n",
      "[6]\tcv-test-auc:0.8305522+0.0069883866636\tcv-train-auc:0.8483712+0.00114111005604\n",
      "[7]\tcv-test-auc:0.8312192+0.00737279353841\tcv-train-auc:0.8490468+0.000940783375703\n",
      "[8]\tcv-test-auc:0.8312028+0.00746654729845\tcv-train-auc:0.849434+0.00116553129516\n",
      "[9]\tcv-test-auc:0.8309764+0.00817816619053\tcv-train-auc:0.8491124+0.00157992412476\n",
      "[10]\tcv-test-auc:0.8315886+0.00777993266295\tcv-train-auc:0.8500682+0.0011168954114\n",
      "[11]\tcv-test-auc:0.830684+0.00706567774527\tcv-train-auc:0.8494032+0.00169421927743\n",
      "[12]\tcv-test-auc:0.830429+0.00722369747429\tcv-train-auc:0.8490228+0.00222536607326\n",
      "[13]\tcv-test-auc:0.8307854+0.00784668616933\tcv-train-auc:0.8491906+0.00282603599411\n",
      "[14]\tcv-test-auc:0.831209+0.00710346073404\tcv-train-auc:0.8496084+0.00203289523586\n",
      "[15]\tcv-test-auc:0.8318358+0.00668279230262\tcv-train-auc:0.8501416+0.00160708127984\n",
      "[16]\tcv-test-auc:0.8323878+0.00662407854422\tcv-train-auc:0.8506972+0.00128663893925\n",
      "[17]\tcv-test-auc:0.8328516+0.00687567415167\tcv-train-auc:0.8511004+0.00116711774899\n",
      "[18]\tcv-test-auc:0.833158+0.00703802966746\tcv-train-auc:0.8514002+0.000812278375928\n",
      "[19]\tcv-test-auc:0.8333414+0.00694902009207\tcv-train-auc:0.8517826+0.000771970362125\n",
      "[20]\tcv-test-auc:0.8335624+0.00674525120659\tcv-train-auc:0.8520232+0.000807250493961\n",
      "[21]\tcv-test-auc:0.833149+0.00681093846691\tcv-train-auc:0.8519064+0.000965046237234\n",
      "[22]\tcv-test-auc:0.8332998+0.00674399390273\tcv-train-auc:0.8521114+0.000890752176534\n",
      "[23]\tcv-test-auc:0.8333796+0.00687329101959\tcv-train-auc:0.8522258+0.000887531723377\n",
      "[24]\tcv-test-auc:0.8333934+0.0069809018787\tcv-train-auc:0.8522296+0.000913645576797\n",
      "[25]\tcv-test-auc:0.8338522+0.00697241781307\tcv-train-auc:0.8525228+0.000864063747648\n",
      "[26]\tcv-test-auc:0.8339526+0.00720398088837\tcv-train-auc:0.8526862+0.000756744976858\n",
      "[27]\tcv-test-auc:0.8341188+0.00728499656554\tcv-train-auc:0.852841+0.000677875504794\n",
      "[28]\tcv-test-auc:0.8340088+0.00727507535081\tcv-train-auc:0.8527338+0.000736235397139\n",
      "[29]\tcv-test-auc:0.8341574+0.00722230266882\tcv-train-auc:0.8529286+0.000671926365013\n",
      "[30]\tcv-test-auc:0.8340442+0.00719065608689\tcv-train-auc:0.8530234+0.000726091068668\n",
      "[31]\tcv-test-auc:0.8341422+0.00723260429997\tcv-train-auc:0.8531408+0.000682107440217\n",
      "[32]\tcv-test-auc:0.8342178+0.00716679304571\tcv-train-auc:0.853254+0.000709396645044\n",
      "[33]\tcv-test-auc:0.8343956+0.00703235694771\tcv-train-auc:0.853368+0.000866556864839\n",
      "[34]\tcv-test-auc:0.834429+0.00710060496014\tcv-train-auc:0.853527+0.000752645201938\n",
      "[35]\tcv-test-auc:0.8343266+0.00718730518623\tcv-train-auc:0.8537624+0.000611190183167\n",
      "[36]\tcv-test-auc:0.834228+0.00708014251269\tcv-train-auc:0.8537896+0.000604631656465\n",
      "[37]\tcv-test-auc:0.8343186+0.00715027248712\tcv-train-auc:0.8539962+0.000592803981093\n",
      "[38]\tcv-test-auc:0.834251+0.00720919826333\tcv-train-auc:0.8540598+0.000657336260981\n",
      "[39]\tcv-test-auc:0.8343414+0.00733103053056\tcv-train-auc:0.8541682+0.000595194556427\n",
      "[40]\tcv-test-auc:0.8343776+0.00737723001133\tcv-train-auc:0.854327+0.000559466531617\n",
      "[41]\tcv-test-auc:0.834533+0.0074454286109\tcv-train-auc:0.8544438+0.000545116281173\n",
      "[42]\tcv-test-auc:0.8346546+0.00734918206605\tcv-train-auc:0.854515+0.000559262013729\n",
      "[43]\tcv-test-auc:0.8347366+0.0072895102332\tcv-train-auc:0.8546118+0.000652079565697\n",
      "[44]\tcv-test-auc:0.834626+0.00705673777322\tcv-train-auc:0.8545976+0.000848835578896\n",
      "[45]\tcv-test-auc:0.8347326+0.0072216823137\tcv-train-auc:0.8547572+0.000755152011187\n",
      "[46]\tcv-test-auc:0.8346548+0.00708074901123\tcv-train-auc:0.8547638+0.000925237569492\n",
      "[47]\tcv-test-auc:0.8348654+0.00715884341497\tcv-train-auc:0.8549882+0.000857673690864\n",
      "[48]\tcv-test-auc:0.8349536+0.0072226961891\tcv-train-auc:0.8550852+0.00080534052425\n",
      "[49]\tcv-test-auc:0.8348646+0.00727054519551\tcv-train-auc:0.8550552+0.000913871413274\n",
      "[50]\tcv-test-auc:0.834878+0.00724435998553\tcv-train-auc:0.855151+0.000886067040353\n",
      "[51]\tcv-test-auc:0.8350442+0.00727591845474\tcv-train-auc:0.8553428+0.000796149583935\n",
      "[52]\tcv-test-auc:0.8350366+0.00719427521297\tcv-train-auc:0.8553614+0.000910225158958\n",
      "[53]\tcv-test-auc:0.8350718+0.00716205859792\tcv-train-auc:0.8555028+0.000821278369373\n",
      "[54]\tcv-test-auc:0.8350814+0.00732180782594\tcv-train-auc:0.855686+0.000771722488982\n",
      "[55]\tcv-test-auc:0.8352438+0.00737041348637\tcv-train-auc:0.8558554+0.000680905749719\n",
      "[56]\tcv-test-auc:0.8352482+0.00741067020991\tcv-train-auc:0.85597+0.000779366922572\n",
      "[57]\tcv-test-auc:0.8352318+0.00742982095074\tcv-train-auc:0.8560394+0.000737789021333\n",
      "[58]\tcv-test-auc:0.8353048+0.00734177758857\tcv-train-auc:0.8561506+0.000725395505914\n",
      "[59]\tcv-test-auc:0.8354994+0.00743581830332\tcv-train-auc:0.8563428+0.000637211236561\n",
      "[60]\tcv-test-auc:0.8354332+0.00737865476628\tcv-train-auc:0.8564624+0.000606645069213\n",
      "[61]\tcv-test-auc:0.8355082+0.00737567020412\tcv-train-auc:0.8565566+0.000571912091147\n",
      "[62]\tcv-test-auc:0.8354944+0.00740443104094\tcv-train-auc:0.8566176+0.000604286223573\n",
      "[63]\tcv-test-auc:0.8355888+0.0073870461864\tcv-train-auc:0.856755+0.000601633443219\n",
      "[64]\tcv-test-auc:0.8357324+0.00740227863837\tcv-train-auc:0.8568112+0.000635527623318\n",
      "[65]\tcv-test-auc:0.835809+0.00740891627703\tcv-train-auc:0.8569092+0.000638751093933\n",
      "[66]\tcv-test-auc:0.8358502+0.00732479633574\tcv-train-auc:0.8570194+0.000612518277278\n",
      "[67]\tcv-test-auc:0.8358338+0.0073296239849\tcv-train-auc:0.857127+0.000598635782425\n",
      "[68]\tcv-test-auc:0.835905+0.00738791927406\tcv-train-auc:0.8572296+0.000613561276483\n",
      "[69]\tcv-test-auc:0.8360018+0.0074137686341\tcv-train-auc:0.8573282+0.000598583461181\n",
      "[70]\tcv-test-auc:0.8360888+0.0073806048641\tcv-train-auc:0.8573952+0.000586390109057\n",
      "[71]\tcv-test-auc:0.8361588+0.00739781455296\tcv-train-auc:0.857509+0.000602726803784\n",
      "[72]\tcv-test-auc:0.8362598+0.00735242067349\tcv-train-auc:0.8576174+0.000545377520622\n",
      "[73]\tcv-test-auc:0.8362954+0.00735924633641\tcv-train-auc:0.8577038+0.000550978547677\n",
      "[74]\tcv-test-auc:0.8363888+0.00733362364456\tcv-train-auc:0.8577832+0.000546337404907\n",
      "[75]\tcv-test-auc:0.8363126+0.00723421784577\tcv-train-auc:0.8578872+0.00054433717492\n",
      "[76]\tcv-test-auc:0.8362944+0.00726811171075\tcv-train-auc:0.858022+0.000513839663708\n",
      "[77]\tcv-test-auc:0.8362766+0.00719882389283\tcv-train-auc:0.858111+0.000512876983301\n",
      "[78]\tcv-test-auc:0.8363338+0.00721861336823\tcv-train-auc:0.858251+0.000488391236613\n",
      "[79]\tcv-test-auc:0.8363586+0.00730151295555\tcv-train-auc:0.8583114+0.000482598632406\n",
      "[80]\tcv-test-auc:0.8363882+0.00736589083275\tcv-train-auc:0.8584356+0.000454374118981\n",
      "[81]\tcv-test-auc:0.8363254+0.00729963882942\tcv-train-auc:0.8585202+0.00043057933067\n",
      "[82]\tcv-test-auc:0.8363466+0.007314195748\tcv-train-auc:0.8585842+0.000420607845861\n",
      "[83]\tcv-test-auc:0.8363638+0.00732782244326\tcv-train-auc:0.8586736+0.000434710294334\n",
      "[84]\tcv-test-auc:0.8363918+0.00736225765374\tcv-train-auc:0.8587836+0.000437303372958\n",
      "[85]\tcv-test-auc:0.836395+0.0073860149201\tcv-train-auc:0.858857+0.000400091489537\n",
      "[86]\tcv-test-auc:0.836438+0.00741314937122\tcv-train-auc:0.8589358+0.000396847779381\n",
      "[87]\tcv-test-auc:0.8364714+0.00743778624592\tcv-train-auc:0.8589972+0.000371827056573\n",
      "[88]\tcv-test-auc:0.8364622+0.00751761255719\tcv-train-auc:0.8590808+0.000407423808828\n",
      "[89]\tcv-test-auc:0.8364726+0.00752344109035\tcv-train-auc:0.859142+0.000444174740389\n",
      "[90]\tcv-test-auc:0.8365588+0.00754265776501\tcv-train-auc:0.8592312+0.000458485506859\n",
      "[91]\tcv-test-auc:0.8365934+0.00753091929581\tcv-train-auc:0.8593162+0.000456342152337\n",
      "[92]\tcv-test-auc:0.8366688+0.00753220967313\tcv-train-auc:0.8593634+0.000473344948214\n",
      "[93]\tcv-test-auc:0.8366836+0.00754765419452\tcv-train-auc:0.8594744+0.000475839720915\n",
      "[94]\tcv-test-auc:0.8367154+0.00755024292589\tcv-train-auc:0.8595566+0.000474725436437\n",
      "[95]\tcv-test-auc:0.8367234+0.00752861077756\tcv-train-auc:0.8596448+0.000485011092657\n",
      "[96]\tcv-test-auc:0.8367398+0.00754521287705\tcv-train-auc:0.8597074+0.000490523638574\n",
      "[97]\tcv-test-auc:0.8367372+0.00752968903475\tcv-train-auc:0.8597834+0.000496346088934\n",
      "[98]\tcv-test-auc:0.836774+0.00759737365147\tcv-train-auc:0.859886+0.000463235577217\n",
      "[99]\tcv-test-auc:0.83682+0.00762777700251\tcv-train-auc:0.859958+0.000467700331409\n",
      "[100]\tcv-test-auc:0.8368386+0.00764324623704\tcv-train-auc:0.860029+0.000489713385563\n",
      "[101]\tcv-test-auc:0.8368562+0.00763049501409\tcv-train-auc:0.8601356+0.000475652225896\n",
      "[102]\tcv-test-auc:0.8368572+0.00762507317735\tcv-train-auc:0.8601882+0.000473727516617\n",
      "[103]\tcv-test-auc:0.8369192+0.00759692167657\tcv-train-auc:0.860254+0.000443997747742\n",
      "[104]\tcv-test-auc:0.8369396+0.00758958169071\tcv-train-auc:0.8603214+0.000450096256372\n",
      "[105]\tcv-test-auc:0.8369688+0.00753667835057\tcv-train-auc:0.8604402+0.000486778553348\n",
      "[106]\tcv-test-auc:0.83709+0.00746268627238\tcv-train-auc:0.8605358+0.000474973851912\n",
      "[107]\tcv-test-auc:0.8371106+0.00744075844521\tcv-train-auc:0.860602+0.000485521163287\n",
      "[108]\tcv-test-auc:0.8370842+0.00740542453611\tcv-train-auc:0.8606966+0.000464297576991\n",
      "[109]\tcv-test-auc:0.8371062+0.00742107653646\tcv-train-auc:0.860774+0.000470198256058\n",
      "[110]\tcv-test-auc:0.8370926+0.00742446761997\tcv-train-auc:0.8608726+0.000482568378574\n",
      "[111]\tcv-test-auc:0.837097+0.00742152208108\tcv-train-auc:0.8609404+0.000490115333366\n",
      "[112]\tcv-test-auc:0.8370836+0.00740397327386\tcv-train-auc:0.8610396+0.000508470097449\n",
      "[113]\tcv-test-auc:0.8370616+0.00733660533489\tcv-train-auc:0.861127+0.000499514964741\n",
      "[114]\tcv-test-auc:0.8370134+0.00734852340542\tcv-train-auc:0.8611794+0.000502766586002\n",
      "[115]\tcv-test-auc:0.837017+0.00738905593429\tcv-train-auc:0.8612726+0.000516464364695\n",
      "[116]\tcv-test-auc:0.837059+0.0073706350337\tcv-train-auc:0.8613506+0.000528141117506\n",
      "[117]\tcv-test-auc:0.8371058+0.00735349090977\tcv-train-auc:0.8614394+0.000531407414325\n",
      "[118]\tcv-test-auc:0.8371266+0.00740623943982\tcv-train-auc:0.8615082+0.000541403878819\n",
      "[119]\tcv-test-auc:0.8371378+0.00740216536967\tcv-train-auc:0.8616014+0.000560550301044\n",
      "[120]\tcv-test-auc:0.8371866+0.00736180300198\tcv-train-auc:0.8616782+0.00054630189456\n",
      "[121]\tcv-test-auc:0.837228+0.00735370293118\tcv-train-auc:0.861763+0.000532642844691\n",
      "[122]\tcv-test-auc:0.8373052+0.00733810180905\tcv-train-auc:0.861862+0.000532166891116\n",
      "[123]\tcv-test-auc:0.8373414+0.00736095595966\tcv-train-auc:0.8619682+0.000527974014512\n",
      "[124]\tcv-test-auc:0.8373542+0.00735874528435\tcv-train-auc:0.8620348+0.000521311576699\n",
      "[125]\tcv-test-auc:0.8374178+0.00735498727123\tcv-train-auc:0.8621154+0.000539725337556\n",
      "[126]\tcv-test-auc:0.8374146+0.00731905555656\tcv-train-auc:0.8621936+0.000552747175479\n",
      "[127]\tcv-test-auc:0.837457+0.00731769540224\tcv-train-auc:0.8622626+0.000554415584197\n",
      "[128]\tcv-test-auc:0.8374476+0.00731054434635\tcv-train-auc:0.8623262+0.000572601571776\n",
      "[129]\tcv-test-auc:0.837472+0.0073057291491\tcv-train-auc:0.8624098+0.000582536316464\n",
      "[130]\tcv-test-auc:0.8374918+0.00726158589841\tcv-train-auc:0.8624886+0.000600502656114\n",
      "[131]\tcv-test-auc:0.8374896+0.00725115920664\tcv-train-auc:0.8625848+0.000626618352748\n",
      "[132]\tcv-test-auc:0.8375034+0.00723201569689\tcv-train-auc:0.8626388+0.000617108547988\n",
      "[133]\tcv-test-auc:0.8374926+0.00725932577035\tcv-train-auc:0.8627088+0.000624763443233\n",
      "[134]\tcv-test-auc:0.8374964+0.00723076202347\tcv-train-auc:0.862758+0.000590746646203\n",
      "[135]\tcv-test-auc:0.8375032+0.00721972169547\tcv-train-auc:0.8628412+0.000585416569632\n",
      "[136]\tcv-test-auc:0.8375454+0.00720861982907\tcv-train-auc:0.8629446+0.000596109251732\n",
      "[137]\tcv-test-auc:0.8375704+0.0072277023071\tcv-train-auc:0.8630418+0.000625306772712\n",
      "[138]\tcv-test-auc:0.8375846+0.00722789110599\tcv-train-auc:0.8631058+0.000620711011663\n",
      "[139]\tcv-test-auc:0.8376118+0.00721746665805\tcv-train-auc:0.8631608+0.000599153870053\n",
      "[140]\tcv-test-auc:0.8375826+0.0072366643863\tcv-train-auc:0.8632408+0.000577452820584\n",
      "[141]\tcv-test-auc:0.8375984+0.00724929189921\tcv-train-auc:0.8633442+0.000585505046947\n",
      "[142]\tcv-test-auc:0.8376262+0.00724834015206\tcv-train-auc:0.8633964+0.000578265544538\n",
      "[143]\tcv-test-auc:0.8376272+0.00725139471826\tcv-train-auc:0.8634526+0.000540376387345\n",
      "[144]\tcv-test-auc:0.8376242+0.00722025003445\tcv-train-auc:0.8635374+0.000562941062634\n",
      "[145]\tcv-test-auc:0.8376524+0.00725125212912\tcv-train-auc:0.8636002+0.000571417325604\n",
      "[146]\tcv-test-auc:0.8376622+0.00724677236844\tcv-train-auc:0.863675+0.000568713284529\n",
      "[147]\tcv-test-auc:0.837683+0.00724892267858\tcv-train-auc:0.8637654+0.000564506368432\n",
      "[148]\tcv-test-auc:0.8376896+0.00725266559549\tcv-train-auc:0.8638402+0.000571433075697\n",
      "[149]\tcv-test-auc:0.837726+0.0071943057483\tcv-train-auc:0.86393+0.00057317955302\n",
      "[150]\tcv-test-auc:0.837726+0.00716108421959\tcv-train-auc:0.8640066+0.000609775893259\n",
      "[151]\tcv-test-auc:0.8377362+0.00713799303446\tcv-train-auc:0.864065+0.000608327872122\n",
      "[152]\tcv-test-auc:0.8377454+0.00712798228393\tcv-train-auc:0.8641466+0.000613445221678\n",
      "[153]\tcv-test-auc:0.8377808+0.00706622661397\tcv-train-auc:0.8642064+0.000608121566794\n",
      "[154]\tcv-test-auc:0.8377914+0.00712230259396\tcv-train-auc:0.8642686+0.000603944566993\n",
      "[155]\tcv-test-auc:0.8378044+0.00707850240093\tcv-train-auc:0.864361+0.000612183632581\n",
      "[156]\tcv-test-auc:0.8378434+0.00708312017687\tcv-train-auc:0.8644456+0.00060905750139\n",
      "[157]\tcv-test-auc:0.8378366+0.00710213482271\tcv-train-auc:0.8645228+0.000624698775411\n",
      "[158]\tcv-test-auc:0.8378222+0.00706643704847\tcv-train-auc:0.8646262+0.000633875508282\n",
      "[159]\tcv-test-auc:0.8378302+0.00705838928935\tcv-train-auc:0.8646986+0.000625507985561\n",
      "[160]\tcv-test-auc:0.8378616+0.00703799782893\tcv-train-auc:0.8647738+0.000658922575118\n",
      "[161]\tcv-test-auc:0.8378782+0.0070108111485\tcv-train-auc:0.8648518+0.000627869859127\n",
      "[162]\tcv-test-auc:0.8378638+0.00700035791656\tcv-train-auc:0.8649252+0.000651984785099\n",
      "[163]\tcv-test-auc:0.8378806+0.00700141196045\tcv-train-auc:0.8649752+0.000656541361987\n",
      "[164]\tcv-test-auc:0.8378982+0.00697315619788\tcv-train-auc:0.865055+0.000613063455117\n",
      "[165]\tcv-test-auc:0.837899+0.00693675708094\tcv-train-auc:0.8651142+0.000589065497207\n",
      "[166]\tcv-test-auc:0.837912+0.00692934963759\tcv-train-auc:0.8651918+0.000614871824041\n",
      "[167]\tcv-test-auc:0.837932+0.00691116615341\tcv-train-auc:0.8652766+0.000589223081693\n",
      "[168]\tcv-test-auc:0.8379498+0.00688464591392\tcv-train-auc:0.865359+0.000578400207469\n",
      "[169]\tcv-test-auc:0.837974+0.0068808477094\tcv-train-auc:0.8654378+0.000567174188411\n",
      "[170]\tcv-test-auc:0.8379912+0.00686697818258\tcv-train-auc:0.865511+0.0005380442361\n",
      "[171]\tcv-test-auc:0.8379864+0.0068728146374\tcv-train-auc:0.8656022+0.000521058307678\n",
      "[172]\tcv-test-auc:0.8379904+0.00687002185149\tcv-train-auc:0.8656656+0.000507305667226\n",
      "[173]\tcv-test-auc:0.8380076+0.00688368745949\tcv-train-auc:0.865749+0.000476879859084\n",
      "[174]\tcv-test-auc:0.8379838+0.00690343854612\tcv-train-auc:0.8658212+0.00046656506513\n",
      "[175]\tcv-test-auc:0.8379772+0.00687802824653\tcv-train-auc:0.865897+0.000456038156298\n",
      "[176]\tcv-test-auc:0.8379952+0.00688167134932\tcv-train-auc:0.865965+0.000457942791187\n",
      "[177]\tcv-test-auc:0.8379832+0.00689977197884\tcv-train-auc:0.8660322+0.000446876448249\n",
      "[178]\tcv-test-auc:0.8380146+0.00691646197416\tcv-train-auc:0.8660962+0.000467964699523\n",
      "[179]\tcv-test-auc:0.8379858+0.00689501348512\tcv-train-auc:0.8661862+0.000484373987741\n",
      "[180]\tcv-test-auc:0.8379962+0.00686204635368\tcv-train-auc:0.8662358+0.000486198066635\n",
      "[181]\tcv-test-auc:0.8380084+0.00686162685083\tcv-train-auc:0.8663106+0.000490102275041\n",
      "[182]\tcv-test-auc:0.8380534+0.00683447480352\tcv-train-auc:0.8663888+0.000489114874033\n",
      "[183]\tcv-test-auc:0.8380666+0.0068646986416\tcv-train-auc:0.8664736+0.000492780924956\n",
      "[184]\tcv-test-auc:0.8380608+0.00684974894138\tcv-train-auc:0.8665628+0.000485645714487\n",
      "[185]\tcv-test-auc:0.8380732+0.00687717469314\tcv-train-auc:0.8666536+0.000479763941955\n",
      "[186]\tcv-test-auc:0.8380624+0.00688254140852\tcv-train-auc:0.866721+0.000480201207829\n",
      "[187]\tcv-test-auc:0.8380576+0.00687999071511\tcv-train-auc:0.866798+0.000489374703065\n",
      "[188]\tcv-test-auc:0.8380562+0.00686991465449\tcv-train-auc:0.8668674+0.00049295338522\n",
      "[189]\tcv-test-auc:0.8381154+0.0068804541885\tcv-train-auc:0.8669362+0.000504433702284\n",
      "[190]\tcv-test-auc:0.8381496+0.00686073566318\tcv-train-auc:0.8670188+0.000495491432822\n",
      "[191]\tcv-test-auc:0.8381562+0.00686661588849\tcv-train-auc:0.867103+0.000486680593408\n",
      "[192]\tcv-test-auc:0.8381982+0.00689166843079\tcv-train-auc:0.8671712+0.000482349416917\n",
      "[193]\tcv-test-auc:0.8381834+0.00690730698898\tcv-train-auc:0.8672346+0.00047893281366\n",
      "[194]\tcv-test-auc:0.8381788+0.00693441641092\tcv-train-auc:0.8672842+0.000490938040897\n",
      "[195]\tcv-test-auc:0.838183+0.00689098245535\tcv-train-auc:0.8673616+0.000500922988093\n",
      "[196]\tcv-test-auc:0.838192+0.00690012370904\tcv-train-auc:0.8674174+0.000497305781185\n",
      "[197]\tcv-test-auc:0.8382036+0.00692675533277\tcv-train-auc:0.8674846+0.000492919709486\n",
      "[198]\tcv-test-auc:0.8382042+0.00694714972921\tcv-train-auc:0.8675438+0.000506823203889\n",
      "[199]\tcv-test-auc:0.8382246+0.0069415406532\tcv-train-auc:0.8676196+0.000512063902262\n",
      "[200]\tcv-test-auc:0.8382318+0.00695341620788\tcv-train-auc:0.8676918+0.000527702719341\n",
      "[201]\tcv-test-auc:0.8382538+0.00694808046586\tcv-train-auc:0.8677672+0.000522090183781\n",
      "[202]\tcv-test-auc:0.8382532+0.00696209639117\tcv-train-auc:0.8678538+0.000507926136362\n",
      "[203]\tcv-test-auc:0.838275+0.00696223774371\tcv-train-auc:0.867923+0.000513834214509\n",
      "[204]\tcv-test-auc:0.8382608+0.00695223553686\tcv-train-auc:0.8680034+0.000491338009928\n",
      "[205]\tcv-test-auc:0.8382664+0.00696703984774\tcv-train-auc:0.8680906+0.000490085951645\n",
      "[206]\tcv-test-auc:0.8382878+0.00697891353722\tcv-train-auc:0.86816+0.00049265728453\n",
      "[207]\tcv-test-auc:0.8383038+0.00698067404768\tcv-train-auc:0.8682136+0.000489406415978\n",
      "[208]\tcv-test-auc:0.8383316+0.00699686540102\tcv-train-auc:0.868275+0.000494693844716\n",
      "[209]\tcv-test-auc:0.8383346+0.00696968190379\tcv-train-auc:0.868333+0.000503451288607\n",
      "[210]\tcv-test-auc:0.8383286+0.00694396395728\tcv-train-auc:0.8684024+0.000507939208961\n",
      "[211]\tcv-test-auc:0.8383246+0.00693591815407\tcv-train-auc:0.868478+0.000511944918912\n",
      "[212]\tcv-test-auc:0.8383344+0.006898486779\tcv-train-auc:0.8685574+0.000489614378874\n",
      "[213]\tcv-test-auc:0.8383322+0.00688575751534\tcv-train-auc:0.8686258+0.000479410221001\n",
      "[214]\tcv-test-auc:0.8383604+0.00687894310487\tcv-train-auc:0.8686982+0.000481224853889\n",
      "[215]\tcv-test-auc:0.8383656+0.00686716414832\tcv-train-auc:0.8687702+0.000491111962795\n",
      "[216]\tcv-test-auc:0.8383788+0.00684049478912\tcv-train-auc:0.8688404+0.000494474104479\n",
      "[217]\tcv-test-auc:0.838392+0.00680772669839\tcv-train-auc:0.8689082+0.0004836\n",
      "[218]\tcv-test-auc:0.8384012+0.00682516828804\tcv-train-auc:0.8689688+0.000490167073558\n",
      "[219]\tcv-test-auc:0.8384+0.00681116744766\tcv-train-auc:0.8690418+0.000461800129926\n",
      "[220]\tcv-test-auc:0.8383882+0.00681353674387\tcv-train-auc:0.869112+0.000456121913528\n",
      "[221]\tcv-test-auc:0.8384082+0.00677746794607\tcv-train-auc:0.8691808+0.000457318882182\n",
      "[222]\tcv-test-auc:0.8384022+0.00675580181474\tcv-train-auc:0.8692516+0.000445439827586\n",
      "[223]\tcv-test-auc:0.8384274+0.00672572582254\tcv-train-auc:0.869321+0.000452805035308\n",
      "[224]\tcv-test-auc:0.8384272+0.00669659219006\tcv-train-auc:0.8693912+0.000450787488735\n",
      "[225]\tcv-test-auc:0.8384118+0.0066951971263\tcv-train-auc:0.869456+0.000458154559074\n",
      "[226]\tcv-test-auc:0.8384+0.00669440470841\tcv-train-auc:0.8695136+0.000454785487895\n",
      "[227]\tcv-test-auc:0.8384064+0.0066881300406\tcv-train-auc:0.8695804+0.000467638578391\n",
      "[228]\tcv-test-auc:0.838413+0.00668356318142\tcv-train-auc:0.8696434+0.000474266423016\n",
      "[229]\tcv-test-auc:0.8384496+0.00666058963156\tcv-train-auc:0.8697068+0.000468105287302\n",
      "[230]\tcv-test-auc:0.838455+0.00663873156559\tcv-train-auc:0.8697932+0.000466149932961\n",
      "[231]\tcv-test-auc:0.8384598+0.00664634923548\tcv-train-auc:0.8698714+0.000444782913341\n",
      "[232]\tcv-test-auc:0.838461+0.00664287838215\tcv-train-auc:0.8699382+0.000435106607626\n",
      "[233]\tcv-test-auc:0.8384426+0.00663501049283\tcv-train-auc:0.8700012+0.000437355873403\n",
      "[234]\tcv-test-auc:0.8384442+0.00663586737059\tcv-train-auc:0.870058+0.00043899658313\n",
      "[235]\tcv-test-auc:0.8384512+0.00661364841521\tcv-train-auc:0.8701296+0.000438339411872\n",
      "[236]\tcv-test-auc:0.838438+0.00661548410927\tcv-train-auc:0.870181+0.000431955553269\n",
      "[237]\tcv-test-auc:0.8384432+0.00662400300121\tcv-train-auc:0.8702524+0.000411072061809\n",
      "[238]\tcv-test-auc:0.8384414+0.00659687433865\tcv-train-auc:0.8703342+0.00040733200218\n",
      "[239]\tcv-test-auc:0.8384784+0.00660505868558\tcv-train-auc:0.8704256+0.000399429893724\n",
      "[240]\tcv-test-auc:0.8385022+0.00659450854575\tcv-train-auc:0.8705126+0.000393176092864\n",
      "[241]\tcv-test-auc:0.8385194+0.0065733876989\tcv-train-auc:0.870576+0.000382645005194\n",
      "[242]\tcv-test-auc:0.8385138+0.00659021284634\tcv-train-auc:0.8706366+0.000395361404287\n",
      "[243]\tcv-test-auc:0.8385282+0.00660016413129\tcv-train-auc:0.8707054+0.000403239184604\n",
      "[244]\tcv-test-auc:0.8385344+0.00659293417531\tcv-train-auc:0.8707714+0.000385477677694\n",
      "[245]\tcv-test-auc:0.8385306+0.00662222906883\tcv-train-auc:0.8708368+0.000387851208584\n",
      "[246]\tcv-test-auc:0.838503+0.00659432140557\tcv-train-auc:0.8708804+0.000386462727828\n",
      "[247]\tcv-test-auc:0.8385352+0.0065899768558\tcv-train-auc:0.870936+0.000381187617847\n",
      "[248]\tcv-test-auc:0.8385318+0.00659625522247\tcv-train-auc:0.8710022+0.000395879476609\n",
      "[249]\tcv-test-auc:0.8385412+0.00659190847631\tcv-train-auc:0.871072+0.000394171536263\n",
      "[250]\tcv-test-auc:0.8385212+0.00659748941341\tcv-train-auc:0.8711504+0.000407331118379\n",
      "[251]\tcv-test-auc:0.8385412+0.00659883166629\tcv-train-auc:0.871209+0.000413358440098\n",
      "[252]\tcv-test-auc:0.8385456+0.00659211215317\tcv-train-auc:0.8712818+0.000429327101404\n",
      "[253]\tcv-test-auc:0.8385536+0.00659499260348\tcv-train-auc:0.8713436+0.00042387290548\n",
      "[254]\tcv-test-auc:0.8385418+0.00659222707133\tcv-train-auc:0.8713924+0.000419686359083\n",
      "[255]\tcv-test-auc:0.8385178+0.00659771940598\tcv-train-auc:0.8714548+0.000410610959425\n",
      "[256]\tcv-test-auc:0.8385062+0.00658919459115\tcv-train-auc:0.8715212+0.000403471634691\n",
      "[257]\tcv-test-auc:0.8384936+0.006594852617\tcv-train-auc:0.8715776+0.000425423365602\n",
      "[258]\tcv-test-auc:0.838478+0.00659810045392\tcv-train-auc:0.8716366+0.000433653133276\n",
      "[259]\tcv-test-auc:0.8384764+0.00659004936552\tcv-train-auc:0.871698+0.000429323654135\n",
      "[260]\tcv-test-auc:0.8384928+0.00658175594807\tcv-train-auc:0.8717696+0.000411046274767\n",
      "[261]\tcv-test-auc:0.8384868+0.00660122732225\tcv-train-auc:0.8718424+0.000386675367718\n",
      "[262]\tcv-test-auc:0.8384752+0.00660074887873\tcv-train-auc:0.8719028+0.000391676601292\n",
      "[263]\tcv-test-auc:0.8384716+0.00656229315407\tcv-train-auc:0.871955+0.000396640895521\n",
      "[264]\tcv-test-auc:0.838478+0.00658106100868\tcv-train-auc:0.872021+0.000403145135156\n",
      "[265]\tcv-test-auc:0.8384738+0.00657099214427\tcv-train-auc:0.8720906+0.000390027486211\n",
      "[266]\tcv-test-auc:0.8384626+0.00656691101204\tcv-train-auc:0.872162+0.000380446053995\n",
      "[267]\tcv-test-auc:0.8384666+0.00654878402759\tcv-train-auc:0.8722132+0.000381573793649\n",
      "[268]\tcv-test-auc:0.8384974+0.00652494578062\tcv-train-auc:0.8722826+0.000391407511425\n",
      "[269]\tcv-test-auc:0.8384868+0.00654317456286\tcv-train-auc:0.872344+0.000375161298644\n",
      "[270]\tcv-test-auc:0.8385174+0.00654899438387\tcv-train-auc:0.8723988+0.000363924387751\n",
      "[271]\tcv-test-auc:0.8385312+0.00650205507205\tcv-train-auc:0.8724652+0.00036865615416\n",
      "[272]\tcv-test-auc:0.8385258+0.00649938970673\tcv-train-auc:0.8725362+0.00038342634234\n",
      "[273]\tcv-test-auc:0.8385386+0.00649415412814\tcv-train-auc:0.872577+0.000382710856914\n",
      "[274]\tcv-test-auc:0.8385324+0.00647942758583\tcv-train-auc:0.8726414+0.000372937313767\n",
      "[275]\tcv-test-auc:0.838546+0.00645769971429\tcv-train-auc:0.8727052+0.000379219936185\n",
      "[276]\tcv-test-auc:0.8385252+0.00647046512702\tcv-train-auc:0.8727772+0.000395699077583\n",
      "[277]\tcv-test-auc:0.838545+0.00648318955453\tcv-train-auc:0.8728602+0.00037487139128\n",
      "[278]\tcv-test-auc:0.8385318+0.00647400813716\tcv-train-auc:0.8729374+0.000374045237906\n",
      "[279]\tcv-test-auc:0.8385246+0.00647269917731\tcv-train-auc:0.8730022+0.00038033848083\n",
      "[280]\tcv-test-auc:0.8385498+0.0064691893588\tcv-train-auc:0.873055+0.000364597860663\n",
      "[281]\tcv-test-auc:0.8385428+0.00646440782748\tcv-train-auc:0.8731168+0.000366466042083\n",
      "[282]\tcv-test-auc:0.8385762+0.00645144741589\tcv-train-auc:0.8731702+0.000374030159212\n",
      "[283]\tcv-test-auc:0.8385454+0.00644867368069\tcv-train-auc:0.8732278+0.000379496192339\n",
      "[284]\tcv-test-auc:0.8385226+0.0064488211822\tcv-train-auc:0.8732866+0.000373764952878\n",
      "[285]\tcv-test-auc:0.8385356+0.0064422818504\tcv-train-auc:0.8733558+0.000353652597898\n",
      "[286]\tcv-test-auc:0.8385446+0.00644914796233\tcv-train-auc:0.8734164+0.000364236516566\n",
      "[287]\tcv-test-auc:0.8385608+0.00644640192355\tcv-train-auc:0.8734816+0.000366833259125\n",
      "[288]\tcv-test-auc:0.838552+0.00643531537689\tcv-train-auc:0.8735418+0.000375949145497\n",
      "[289]\tcv-test-auc:0.8385542+0.00643254479658\tcv-train-auc:0.873596+0.000385701957475\n",
      "[290]\tcv-test-auc:0.8385506+0.00643962323743\tcv-train-auc:0.8736376+0.000385823068258\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-30ff397ad033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a2df2b879cf8>\u001b[0m in \u001b[0;36mmodelfit\u001b[0;34m(alg, X_train, y_train, useTrainCV, cv_folds, early_stopping_rounds, show_progress)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mxgtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n\u001b[0;32m---> 11\u001b[0;31m                           metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=show_progress)\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0malg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcvresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mcvresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, show_progress, show_stdv, seed)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         res = aggcv([f.eval(i, feval) for f in cvfolds],\n\u001b[1;32m    420\u001b[0m                     \u001b[0mshow_stdv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_stdv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelfit(xgb1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Tune Max_Depth and min_Child_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to new file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   2 jobs       | elapsed:   20.9s\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   1 jobs       | elapsed:   21.0s\n",
      "[Parallel(n_jobs=2)]: Done   3 jobs       | elapsed:   42.7s\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   4 jobs       | elapsed:   42.9s\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   5 jobs       | elapsed:  1.1min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   6 jobs       | elapsed:  1.1min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   7 jobs       | elapsed:  1.5min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   8 jobs       | elapsed:  1.5min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   9 jobs       | elapsed:  1.9min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "[Parallel(n_jobs=2)]: Done  10 jobs       | elapsed:  1.9min\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  11 jobs       | elapsed:  2.3min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  12 jobs       | elapsed:  2.3min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  13 jobs       | elapsed:  2.7min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  14 jobs       | elapsed:  2.7min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  15 jobs       | elapsed:  3.0min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  16 jobs       | elapsed:  3.2min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  17 jobs       | elapsed:  3.5min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  18 jobs       | elapsed:  3.8min\n",
      "Memmaping (shape=(76020, 306), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_30946_4328736208/30946-4483234704-4355148176-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  19 jobs       | elapsed:  4.1min\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.830440 -  20.5s[CV] ........ max_depth=3, min_child_weight=1, score=0.825767 -  20.5s\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=1, score=0.849305 -  21.9s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.836933 -  21.7s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=3, score=0.830440 -  23.3s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.831266 -  23.3s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=3 .................................[CV] ........ max_depth=3, min_child_weight=3, score=0.836933 -  25.1s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=3, score=0.825767 -  25.2s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=3 .................................[CV] ........ max_depth=3, min_child_weight=3, score=0.831266 -  22.9s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=3, score=0.849305 -  22.9s[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=5 .................................[CV] ........ max_depth=3, min_child_weight=5, score=0.825767 -  24.3s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.830439 -  24.2s[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.849392 -  22.6s[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.836934 -  22.6s[CV] ........ max_depth=5, min_child_weight=1, score=0.832455 -  32.8s\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=5 .................................[CV] max_depth=5, min_child_weight=1 .................................\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.831187 -  20.2s[CV] ........ max_depth=5, min_child_weight=1, score=0.841241 -  31.6s\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=1 .................................[CV] max_depth=5, min_child_weight=1 .................................\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=1, score=0.827304 -  30.6s\n",
      "[CV] max_depth=5, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=1, score=0.853144 -  32.4s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-98688312a4dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                  \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                 verbose=1000)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \"\"\"\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    503\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 505\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m                 for train, test in cv)\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    664\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/apple/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    530\u001b[0m                             \u001b[0;31m# We can now allow subprocesses again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__JOBLIB_SPAWNED_PARALLEL__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m                         \u001b[0;31m# Capture exception to add information on the local\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_test1 = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=31, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                 objective= 'binary:logistic', nthread=4, scale_pos_weight=(len(y_train)-sum(y_train))/sum(y_train)\n",
    "                                                  , seed=27), \n",
    "                                                 param_grid = param_test1, scoring='roc_auc',n_jobs=2,iid=False, cv=5, \n",
    "                                                verbose=1000)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# searching for more optimum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83977, std: 0.00903, params: {'max_depth': 4, 'min_child_weight': 2},\n",
       "  mean: 0.83993, std: 0.00879, params: {'max_depth': 4, 'min_child_weight': 3},\n",
       "  mean: 0.83939, std: 0.00928, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.83995, std: 0.00866, params: {'max_depth': 5, 'min_child_weight': 2},\n",
       "  mean: 0.84055, std: 0.00855, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.84012, std: 0.00910, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: 0.83859, std: 0.00946, params: {'max_depth': 6, 'min_child_weight': 2},\n",
       "  mean: 0.83917, std: 0.00824, params: {'max_depth': 6, 'min_child_weight': 3},\n",
       "  mean: 0.84022, std: 0.00877, params: {'max_depth': 6, 'min_child_weight': 4}],\n",
       " {'max_depth': 5, 'min_child_weight': 3},\n",
       " 0.84054568210341452)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#3. Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84055, std: 0.00855, params: {'gamma': 0.0},\n",
       "  mean: 0.84008, std: 0.00864, params: {'gamma': 0.1},\n",
       "  mean: 0.83951, std: 0.00919, params: {'gamma': 0.2},\n",
       "  mean: 0.83993, std: 0.00896, params: {'gamma': 0.3},\n",
       "  mean: 0.83969, std: 0.00898, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.0},\n",
       " 0.84054568210341452)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This shows that our original value of gamma, i.e. 0 is the optimum one. Before proceeding, a good idea would be to re-calibrate the number of boosting rounds for the updated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 75 rounds.\n",
      "Stopping. Best iteration: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.765040      0.047673        0.775638       0.045115\n",
      "1        0.804597      0.014327        0.815781       0.006890\n",
      "2        0.808440      0.017670        0.820612       0.007208\n",
      "3        0.812558      0.018928        0.824634       0.011052\n",
      "4        0.814372      0.014797        0.827276       0.005470\n",
      "5        0.815404      0.011688        0.829150       0.005696\n",
      "6        0.817367      0.010937        0.831988       0.007426\n",
      "7        0.820128      0.009868        0.835253       0.004960\n",
      "8        0.820196      0.010866        0.836122       0.003272\n",
      "9        0.822151      0.009638        0.838940       0.002889\n",
      "10       0.825126      0.007775        0.841629       0.002382\n",
      "11       0.826819      0.007185        0.843270       0.002261\n",
      "12       0.826916      0.008019        0.843412       0.000861\n",
      "13       0.828277      0.007417        0.845159       0.001112\n",
      "14       0.828938      0.007303        0.845927       0.001994\n",
      "15       0.829325      0.006818        0.846703       0.001967\n",
      "16       0.829786      0.006844        0.847678       0.001700\n",
      "17       0.830031      0.006510        0.848241       0.002252\n",
      "18       0.830202      0.006127        0.848822       0.003106\n",
      "19       0.830870      0.006210        0.849718       0.002104\n",
      "20       0.831096      0.006422        0.850561       0.002487\n",
      "21       0.831663      0.006387        0.851409       0.001806\n",
      "22       0.831568      0.006369        0.851733       0.002148\n",
      "23       0.831819      0.006111        0.852428       0.001571\n",
      "24       0.832626      0.006172        0.853386       0.001216\n",
      "25       0.832418      0.005947        0.853556       0.001459\n",
      "26       0.832210      0.005949        0.854093       0.001276\n",
      "27       0.832601      0.005269        0.854677       0.001570\n",
      "28       0.833611      0.005415        0.856010       0.001158\n",
      "29       0.833935      0.005820        0.856670       0.000860\n",
      "..            ...           ...             ...            ...\n",
      "45       0.838242      0.005601        0.866769       0.000750\n",
      "46       0.838212      0.005560        0.867346       0.000750\n",
      "47       0.838423      0.005357        0.867751       0.000797\n",
      "48       0.838640      0.005293        0.868220       0.000797\n",
      "49       0.838635      0.005265        0.868595       0.000752\n",
      "50       0.838811      0.005127        0.868924       0.000780\n",
      "51       0.838813      0.005000        0.869381       0.000849\n",
      "52       0.838777      0.004954        0.869902       0.000805\n",
      "53       0.838776      0.004913        0.870346       0.000639\n",
      "54       0.838855      0.004982        0.870689       0.000588\n",
      "55       0.839000      0.005024        0.871035       0.000632\n",
      "56       0.839068      0.005053        0.871358       0.000563\n",
      "57       0.838934      0.005106        0.871841       0.000482\n",
      "58       0.838967      0.005103        0.872179       0.000489\n",
      "59       0.838925      0.005155        0.872476       0.000496\n",
      "60       0.839025      0.005137        0.872947       0.000579\n",
      "61       0.839123      0.005071        0.873182       0.000634\n",
      "62       0.839098      0.005089        0.873580       0.000741\n",
      "63       0.839067      0.005050        0.873963       0.000698\n",
      "64       0.839113      0.005059        0.874251       0.000727\n",
      "65       0.839020      0.004943        0.874539       0.000721\n",
      "66       0.839052      0.004934        0.874893       0.000698\n",
      "67       0.839031      0.004796        0.875275       0.000828\n",
      "68       0.838909      0.004679        0.875593       0.000921\n",
      "69       0.838909      0.004552        0.875953       0.000803\n",
      "70       0.838946      0.004542        0.876451       0.000815\n",
      "71       0.839002      0.004548        0.876761       0.000859\n",
      "72       0.838994      0.004554        0.876959       0.000901\n",
      "73       0.839024      0.004607        0.877214       0.000901\n",
      "74       0.839205      0.004563        0.877718       0.001011\n",
      "\n",
      "[75 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9609\n",
      "AUC Score (Train): 0.871105\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, X_train, y_train,early_stopping_rounds=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing awesome got. Will use the same no of trees as was using previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83992, std: 0.00870, params: {'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84032, std: 0.00879, params: {'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84023, std: 0.00912, params: {'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84030, std: 0.00912, params: {'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       "  mean: 0.83913, std: 0.00859, params: {'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83957, std: 0.00821, params: {'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83974, std: 0.00924, params: {'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       "  mean: 0.84039, std: 0.00866, params: {'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83894, std: 0.00921, params: {'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83945, std: 0.00874, params: {'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84055, std: 0.00855, params: {'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84058, std: 0.00920, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83935, std: 0.00946, params: {'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83972, std: 0.00923, params: {'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83981, std: 0.00946, params: {'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83945, std: 0.00942, params: {'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       " 0.8405757633860711)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.05 intervals around these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83946, std: 0.00911, params: {'subsample': 0.85, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83968, std: 0.00908, params: {'subsample': 0.9, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83971, std: 0.00937, params: {'subsample': 0.95, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83972, std: 0.00886, params: {'subsample': 0.85, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84058, std: 0.00920, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84008, std: 0.00876, params: {'subsample': 0.95, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83981, std: 0.00893, params: {'subsample': 0.85, 'colsample_bytree': 0.85},\n",
       "  mean: 0.84041, std: 0.00923, params: {'subsample': 0.9, 'colsample_bytree': 0.85},\n",
       "  mean: 0.84007, std: 0.00857, params: {'subsample': 0.95, 'colsample_bytree': 0.85}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       " 0.8405757633860711)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(85,100,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84058, std: 0.00920, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.84025, std: 0.00924, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.83985, std: 0.00872, params: {'reg_alpha': 0.1},\n",
       "  mean: 0.84018, std: 0.00886, params: {'reg_alpha': 1},\n",
       "  mean: 0.82964, std: 0.00838, params: {'reg_alpha': 100}],\n",
       " {'reg_alpha': 1e-05},\n",
       " 0.84057580892653583)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train,y_train)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Step 6: Reducing Learning Rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "[0]\tcv-test-auc:0.7668878+0.0447758819741\tcv-train-auc:0.7764546+0.0421354577979\n",
      "[1]\tcv-test-auc:0.8025282+0.0135798352479\tcv-train-auc:0.8141794+0.0045415561474\n",
      "[2]\tcv-test-auc:0.8078562+0.017067371636\tcv-train-auc:0.8198564+0.00740330335999\n",
      "[3]\tcv-test-auc:0.810158+0.0160780984323\tcv-train-auc:0.8219422+0.00840285323923\n",
      "[4]\tcv-test-auc:0.8127858+0.0134836377198\tcv-train-auc:0.8248904+0.00548050211568\n",
      "[5]\tcv-test-auc:0.8125252+0.0137919171459\tcv-train-auc:0.824738+0.00683081450487\n",
      "[6]\tcv-test-auc:0.815006+0.0118980251975\tcv-train-auc:0.8265252+0.00682582435754\n",
      "[7]\tcv-test-auc:0.8182028+0.0108325162063\tcv-train-auc:0.830798+0.00439759384209\n",
      "[8]\tcv-test-auc:0.8180468+0.0108898902364\tcv-train-auc:0.8313988+0.00342016230024\n",
      "[9]\tcv-test-auc:0.8190282+0.0104964543995\tcv-train-auc:0.8326366+0.00266678567568\n",
      "[10]\tcv-test-auc:0.8203448+0.00962782046779\tcv-train-auc:0.8340058+0.00222084338935\n",
      "[11]\tcv-test-auc:0.8215928+0.00928683449621\tcv-train-auc:0.8355502+0.00188635091115\n",
      "[12]\tcv-test-auc:0.8210096+0.0109442220665\tcv-train-auc:0.8352504+0.00228615945201\n",
      "[13]\tcv-test-auc:0.822265+0.0105155539654\tcv-train-auc:0.8364306+0.00192209995578\n",
      "[14]\tcv-test-auc:0.8230296+0.0101566405982\tcv-train-auc:0.8370028+0.00157028512061\n",
      "[15]\tcv-test-auc:0.824278+0.00919706931582\tcv-train-auc:0.8383424+0.00141064986442\n",
      "[16]\tcv-test-auc:0.8247328+0.0089949084798\tcv-train-auc:0.839051+0.000859715301713\n",
      "[17]\tcv-test-auc:0.8247472+0.00843086788889\tcv-train-auc:0.8392076+0.00160467437195\n",
      "[18]\tcv-test-auc:0.8251766+0.00811758187147\tcv-train-auc:0.8399894+0.00203957334754\n",
      "[19]\tcv-test-auc:0.825537+0.00842071001757\tcv-train-auc:0.8402968+0.00185558555718\n",
      "[20]\tcv-test-auc:0.8255988+0.00808849430735\tcv-train-auc:0.8405272+0.00268934508013\n",
      "[21]\tcv-test-auc:0.8255984+0.00808000414851\tcv-train-auc:0.8407294+0.00183641526894\n",
      "[22]\tcv-test-auc:0.8250102+0.00856304661671\tcv-train-auc:0.840329+0.00240710473391\n",
      "[23]\tcv-test-auc:0.8251702+0.00807713239708\tcv-train-auc:0.8405922+0.00183937765562\n",
      "[24]\tcv-test-auc:0.825982+0.00812481667485\tcv-train-auc:0.8414938+0.00183827064384\n",
      "[25]\tcv-test-auc:0.8258742+0.0075882697738\tcv-train-auc:0.8413002+0.00206751893824\n",
      "[26]\tcv-test-auc:0.825794+0.00735032034676\tcv-train-auc:0.841493+0.00172698488702\n",
      "[27]\tcv-test-auc:0.8259072+0.00689792137966\tcv-train-auc:0.8416272+0.00161086640042\n",
      "[28]\tcv-test-auc:0.826599+0.00679568415982\tcv-train-auc:0.8425568+0.00196521046201\n",
      "[29]\tcv-test-auc:0.8269578+0.00711623454925\tcv-train-auc:0.842897+0.00195386857286\n",
      "[30]\tcv-test-auc:0.827051+0.00701962597294\tcv-train-auc:0.8430008+0.00220383197182\n",
      "[31]\tcv-test-auc:0.8273608+0.00716984751302\tcv-train-auc:0.8433482+0.00217121895718\n",
      "[32]\tcv-test-auc:0.8278196+0.00705818547787\tcv-train-auc:0.844018+0.00224299371377\n",
      "[33]\tcv-test-auc:0.8279014+0.00689082652807\tcv-train-auc:0.8443656+0.00212207046066\n",
      "[34]\tcv-test-auc:0.82822+0.00690721767429\tcv-train-auc:0.8446582+0.00199595304554\n",
      "[35]\tcv-test-auc:0.8287162+0.00666729391583\tcv-train-auc:0.845274+0.00190047604563\n",
      "[36]\tcv-test-auc:0.828825+0.00730308425256\tcv-train-auc:0.8455412+0.00163985882319\n",
      "[37]\tcv-test-auc:0.8287456+0.00748169367456\tcv-train-auc:0.8458364+0.00132934519219\n",
      "[38]\tcv-test-auc:0.8290438+0.00738713179522\tcv-train-auc:0.8462674+0.00133521887344\n",
      "[39]\tcv-test-auc:0.8289586+0.00725696445079\tcv-train-auc:0.846301+0.00109746835945\n",
      "[40]\tcv-test-auc:0.8286822+0.00708434876047\tcv-train-auc:0.846234+0.0013621192312\n",
      "[41]\tcv-test-auc:0.8291262+0.00699770346328\tcv-train-auc:0.846666+0.00144514497543\n",
      "[42]\tcv-test-auc:0.82898+0.00686003198243\tcv-train-auc:0.8467726+0.00131878771605\n",
      "[43]\tcv-test-auc:0.829199+0.00678363374601\tcv-train-auc:0.8471804+0.00138699107423\n",
      "[44]\tcv-test-auc:0.8293126+0.00672695359282\tcv-train-auc:0.8475434+0.00122567999086\n",
      "[45]\tcv-test-auc:0.829688+0.00670387577451\tcv-train-auc:0.847897+0.00128176331669\n",
      "[46]\tcv-test-auc:0.8299354+0.0065393739945\tcv-train-auc:0.8479788+0.00125722828476\n",
      "[47]\tcv-test-auc:0.8298348+0.00617890143634\tcv-train-auc:0.8482468+0.00141025365094\n",
      "[48]\tcv-test-auc:0.8300872+0.00618205666102\tcv-train-auc:0.8486426+0.00144347741236\n",
      "[49]\tcv-test-auc:0.830176+0.00643902998906\tcv-train-auc:0.8487154+0.00136653687839\n",
      "[50]\tcv-test-auc:0.8302618+0.00653202689523\tcv-train-auc:0.8490604+0.00104671535768\n",
      "[51]\tcv-test-auc:0.8304318+0.00666224302769\tcv-train-auc:0.8492218+0.000837534094828\n",
      "[52]\tcv-test-auc:0.8304542+0.00684921173275\tcv-train-auc:0.8493466+0.000680869620412\n",
      "[53]\tcv-test-auc:0.8307784+0.00671331383446\tcv-train-auc:0.8496048+0.000786871628666\n",
      "[54]\tcv-test-auc:0.830956+0.0067409435838\tcv-train-auc:0.8498512+0.000953062306463\n",
      "[55]\tcv-test-auc:0.8309058+0.00654945553157\tcv-train-auc:0.8500822+0.00109177733994\n",
      "[56]\tcv-test-auc:0.8311484+0.00663360145321\tcv-train-auc:0.8504112+0.0011696661746\n",
      "[57]\tcv-test-auc:0.8310984+0.00648218483538\tcv-train-auc:0.8503888+0.00117665889705\n",
      "[58]\tcv-test-auc:0.8313658+0.0065920559585\tcv-train-auc:0.8507216+0.00130932174808\n",
      "[59]\tcv-test-auc:0.8314142+0.00669039148032\tcv-train-auc:0.850937+0.00133111502133\n",
      "[60]\tcv-test-auc:0.8316188+0.00672997377112\tcv-train-auc:0.8511934+0.00126718405924\n",
      "[61]\tcv-test-auc:0.8319146+0.00664085785422\tcv-train-auc:0.8515564+0.00117326290319\n",
      "[62]\tcv-test-auc:0.8321564+0.00673644477748\tcv-train-auc:0.8516934+0.00103458177057\n",
      "[63]\tcv-test-auc:0.8321686+0.00655529156026\tcv-train-auc:0.8519446+0.00103425230964\n",
      "[64]\tcv-test-auc:0.8322806+0.00640450271606\tcv-train-auc:0.8520896+0.00109540396202\n",
      "[65]\tcv-test-auc:0.8324406+0.00647337845642\tcv-train-auc:0.8523052+0.00108779692958\n",
      "[66]\tcv-test-auc:0.8327316+0.0065672387074\tcv-train-auc:0.8525606+0.0010535930144\n",
      "[67]\tcv-test-auc:0.833024+0.00659954174167\tcv-train-auc:0.8529172+0.000951165895099\n",
      "[68]\tcv-test-auc:0.8329816+0.00650420447403\tcv-train-auc:0.8530892+0.00106878742508\n",
      "[69]\tcv-test-auc:0.8332+0.0065046258309\tcv-train-auc:0.8533298+0.00105718974645\n",
      "[70]\tcv-test-auc:0.8332988+0.00660245031485\tcv-train-auc:0.853589+0.000960868357269\n",
      "[71]\tcv-test-auc:0.8335004+0.00677923720193\tcv-train-auc:0.8537994+0.000934297083373\n",
      "[72]\tcv-test-auc:0.8335456+0.00684234596027\tcv-train-auc:0.853939+0.000890926933031\n",
      "[73]\tcv-test-auc:0.8336382+0.00680948933181\tcv-train-auc:0.8541452+0.000827966762618\n",
      "[74]\tcv-test-auc:0.833732+0.0069127720055\tcv-train-auc:0.8543444+0.000785933992139\n",
      "[75]\tcv-test-auc:0.8338062+0.00681902155445\tcv-train-auc:0.8546164+0.000774224928558\n",
      "[76]\tcv-test-auc:0.8337146+0.00674539975391\tcv-train-auc:0.8547242+0.000817289520305\n",
      "[77]\tcv-test-auc:0.8340074+0.00658726224163\tcv-train-auc:0.8548512+0.000857797971553\n",
      "[78]\tcv-test-auc:0.8340998+0.00656325901972\tcv-train-auc:0.8550554+0.000870355008028\n",
      "[79]\tcv-test-auc:0.8342522+0.00659358474276\tcv-train-auc:0.8552518+0.000840579895072\n",
      "[80]\tcv-test-auc:0.8342342+0.00657848150868\tcv-train-auc:0.8554316+0.000886878480966\n",
      "[81]\tcv-test-auc:0.8344164+0.00656194369375\tcv-train-auc:0.8556462+0.000881238537514\n",
      "[82]\tcv-test-auc:0.8345736+0.0064459485136\tcv-train-auc:0.8558314+0.000928999160387\n",
      "[83]\tcv-test-auc:0.8347424+0.00660605227348\tcv-train-auc:0.8560188+0.000863538395209\n",
      "[84]\tcv-test-auc:0.8348574+0.00659806315823\tcv-train-auc:0.8561812+0.000862621446522\n",
      "[85]\tcv-test-auc:0.835002+0.0066382881227\tcv-train-auc:0.8563944+0.000806745709626\n",
      "[86]\tcv-test-auc:0.8351074+0.00654955548415\tcv-train-auc:0.856471+0.000839080687419\n",
      "[87]\tcv-test-auc:0.8351056+0.00645453361909\tcv-train-auc:0.8566644+0.000771552616482\n",
      "[88]\tcv-test-auc:0.835145+0.00655272264025\tcv-train-auc:0.8567712+0.000771552564638\n",
      "[89]\tcv-test-auc:0.8351844+0.00648487756554\tcv-train-auc:0.85701+0.000758037466093\n",
      "[90]\tcv-test-auc:0.8352042+0.00639294844027\tcv-train-auc:0.857151+0.000691059476456\n",
      "[91]\tcv-test-auc:0.835347+0.00631115732651\tcv-train-auc:0.857434+0.000650839457931\n",
      "[92]\tcv-test-auc:0.835475+0.00634811688613\tcv-train-auc:0.8576114+0.000663721809194\n",
      "[93]\tcv-test-auc:0.8355614+0.00636180039297\tcv-train-auc:0.8578296+0.000697430025164\n",
      "[94]\tcv-test-auc:0.8355698+0.00642730000545\tcv-train-auc:0.8580366+0.000658105341112\n",
      "[95]\tcv-test-auc:0.8357172+0.00635179531786\tcv-train-auc:0.8582384+0.00066742448262\n",
      "[96]\tcv-test-auc:0.8356908+0.00632426170869\tcv-train-auc:0.8583984+0.000606580777803\n",
      "[97]\tcv-test-auc:0.8358622+0.00634147760069\tcv-train-auc:0.8586222+0.000559690057085\n",
      "[98]\tcv-test-auc:0.8358554+0.0062264942817\tcv-train-auc:0.8587814+0.00063798545438\n",
      "[99]\tcv-test-auc:0.8359836+0.00625867032524\tcv-train-auc:0.8589912+0.000723674899385\n",
      "[100]\tcv-test-auc:0.8360654+0.00631466108671\tcv-train-auc:0.8592544+0.000685511371168\n",
      "[101]\tcv-test-auc:0.8360716+0.00624929773975\tcv-train-auc:0.8595318+0.000592519164247\n",
      "[102]\tcv-test-auc:0.8361552+0.0062852249729\tcv-train-auc:0.859774+0.000554713259261\n",
      "[103]\tcv-test-auc:0.8362658+0.0061961526579\tcv-train-auc:0.8600238+0.000563986666509\n",
      "[104]\tcv-test-auc:0.8363184+0.00621280737187\tcv-train-auc:0.8601652+0.000567125171369\n",
      "[105]\tcv-test-auc:0.8364526+0.00621025302544\tcv-train-auc:0.8603594+0.000609531164093\n",
      "[106]\tcv-test-auc:0.8366136+0.00621030555126\tcv-train-auc:0.8605902+0.000601425772644\n",
      "[107]\tcv-test-auc:0.8366572+0.00615760782772\tcv-train-auc:0.8606868+0.00058445509665\n",
      "[108]\tcv-test-auc:0.8366908+0.00609505843778\tcv-train-auc:0.8609068+0.000558896555724\n",
      "[109]\tcv-test-auc:0.8366932+0.00599051969031\tcv-train-auc:0.8611542+0.000557162238491\n",
      "[110]\tcv-test-auc:0.8367652+0.00598256230724\tcv-train-auc:0.8613972+0.000606025544016\n",
      "[111]\tcv-test-auc:0.8368082+0.00589799591048\tcv-train-auc:0.8616262+0.000629866462038\n",
      "[112]\tcv-test-auc:0.8368764+0.00589124491428\tcv-train-auc:0.8617688+0.000600547883187\n",
      "[113]\tcv-test-auc:0.8369054+0.00586414551661\tcv-train-auc:0.861936+0.000553887353168\n",
      "[114]\tcv-test-auc:0.8369+0.00589095330146\tcv-train-auc:0.8621272+0.00052792931345\n",
      "[115]\tcv-test-auc:0.836946+0.00584575986506\tcv-train-auc:0.8622814+0.000510932324286\n",
      "[116]\tcv-test-auc:0.8370262+0.00579698961186\tcv-train-auc:0.8624398+0.000493254254923\n",
      "[117]\tcv-test-auc:0.8371644+0.00576215347244\tcv-train-auc:0.8626142+0.000519234205345\n",
      "[118]\tcv-test-auc:0.8372838+0.00572768446757\tcv-train-auc:0.8628442+0.000439768302632\n",
      "[119]\tcv-test-auc:0.8374216+0.00566712797103\tcv-train-auc:0.8630104+0.000440070721589\n",
      "[120]\tcv-test-auc:0.837517+0.00570364634247\tcv-train-auc:0.8632054+0.000456238797123\n",
      "[121]\tcv-test-auc:0.8375292+0.00570683328651\tcv-train-auc:0.8633838+0.000474499483667\n",
      "[122]\tcv-test-auc:0.8375868+0.0057491951228\tcv-train-auc:0.863565+0.000456717418104\n",
      "[123]\tcv-test-auc:0.8376894+0.00571376672958\tcv-train-auc:0.8637218+0.000493307774113\n",
      "[124]\tcv-test-auc:0.8376976+0.00562705822255\tcv-train-auc:0.8638924+0.000492484964237\n",
      "[125]\tcv-test-auc:0.837759+0.00565724314485\tcv-train-auc:0.8640882+0.000488013688333\n",
      "[126]\tcv-test-auc:0.8378434+0.00567124362376\tcv-train-auc:0.864236+0.000520316057796\n",
      "[127]\tcv-test-auc:0.8378988+0.00561416014734\tcv-train-auc:0.8644346+0.000484284461861\n",
      "[128]\tcv-test-auc:0.8379508+0.00561465323595\tcv-train-auc:0.8646172+0.000525450815967\n",
      "[129]\tcv-test-auc:0.8379658+0.00563367359367\tcv-train-auc:0.864821+0.000506899990136\n",
      "[130]\tcv-test-auc:0.8380076+0.00556157501433\tcv-train-auc:0.864993+0.000473736635695\n",
      "[131]\tcv-test-auc:0.8381016+0.00566723042058\tcv-train-auc:0.8651408+0.000445996591915\n",
      "[132]\tcv-test-auc:0.8381432+0.00566327224844\tcv-train-auc:0.8653576+0.00042340741609\n",
      "[133]\tcv-test-auc:0.8382412+0.0056589153519\tcv-train-auc:0.8655162+0.000433258537135\n",
      "[134]\tcv-test-auc:0.8383614+0.00560782680189\tcv-train-auc:0.8657054+0.000475527748927\n",
      "[135]\tcv-test-auc:0.838361+0.00566203027191\tcv-train-auc:0.8658448+0.000498277994698\n",
      "[136]\tcv-test-auc:0.8384026+0.00566069481954\tcv-train-auc:0.8660266+0.000545208804037\n",
      "[137]\tcv-test-auc:0.8384464+0.00564512014398\tcv-train-auc:0.8661792+0.000533202925723\n",
      "[138]\tcv-test-auc:0.8384818+0.00564503468191\tcv-train-auc:0.8663406+0.000547448116263\n",
      "[139]\tcv-test-auc:0.8385724+0.0055465687267\tcv-train-auc:0.8664952+0.00051823060504\n",
      "[140]\tcv-test-auc:0.8385996+0.00555249229085\tcv-train-auc:0.866626+0.000509434195947\n",
      "[141]\tcv-test-auc:0.8387262+0.00552103593178\tcv-train-auc:0.8667712+0.000514792540739\n",
      "[142]\tcv-test-auc:0.838693+0.00548392228245\tcv-train-auc:0.8669168+0.000520927403771\n",
      "[143]\tcv-test-auc:0.8386812+0.00545074752305\tcv-train-auc:0.8670686+0.000538326518017\n",
      "[144]\tcv-test-auc:0.8386998+0.00542507409719\tcv-train-auc:0.8672452+0.000522230370622\n",
      "[145]\tcv-test-auc:0.8387104+0.00542143252656\tcv-train-auc:0.8674012+0.000545318402404\n",
      "[146]\tcv-test-auc:0.8387728+0.00544661492672\tcv-train-auc:0.8675662+0.000537563912479\n",
      "[147]\tcv-test-auc:0.8388596+0.00541003795181\tcv-train-auc:0.8677088+0.000566833097128\n",
      "[148]\tcv-test-auc:0.8389152+0.00536672713672\tcv-train-auc:0.8678906+0.000551281271222\n",
      "[149]\tcv-test-auc:0.8389304+0.0053382775724\tcv-train-auc:0.8680546+0.000546545368657\n",
      "[150]\tcv-test-auc:0.8389506+0.00530545020144\tcv-train-auc:0.868205+0.00053029840656\n",
      "[151]\tcv-test-auc:0.8390296+0.00526916424493\tcv-train-auc:0.8683606+0.000510928018414\n",
      "[152]\tcv-test-auc:0.8390048+0.00526113373333\tcv-train-auc:0.8685102+0.000513104823598\n",
      "[153]\tcv-test-auc:0.839112+0.00522247607941\tcv-train-auc:0.8686398+0.000493605267395\n",
      "[154]\tcv-test-auc:0.839162+0.00520136197548\tcv-train-auc:0.868784+0.000480400666111\n",
      "[155]\tcv-test-auc:0.8391522+0.00522655417651\tcv-train-auc:0.8689754+0.000534269070787\n",
      "[156]\tcv-test-auc:0.8391916+0.0052280079801\tcv-train-auc:0.8690916+0.0005259831176\n",
      "[157]\tcv-test-auc:0.8392854+0.00517776328544\tcv-train-auc:0.8692324+0.000522485827559\n",
      "[158]\tcv-test-auc:0.8393502+0.00516306542279\tcv-train-auc:0.8693694+0.000551743273634\n",
      "[159]\tcv-test-auc:0.839353+0.00509862997285\tcv-train-auc:0.8695232+0.000546134562173\n",
      "[160]\tcv-test-auc:0.8393906+0.00511630169556\tcv-train-auc:0.8696616+0.000530851617686\n",
      "[161]\tcv-test-auc:0.8394186+0.00513033763411\tcv-train-auc:0.8697712+0.000549870675705\n",
      "[162]\tcv-test-auc:0.839399+0.00514698253349\tcv-train-auc:0.8699432+0.000520534110314\n",
      "[163]\tcv-test-auc:0.8394482+0.00509552797657\tcv-train-auc:0.8700716+0.000528231994487\n",
      "[164]\tcv-test-auc:0.839495+0.00510326769825\tcv-train-auc:0.8702106+0.000539790551974\n",
      "[165]\tcv-test-auc:0.839529+0.00509312069364\tcv-train-auc:0.8703286+0.000544419544102\n",
      "[166]\tcv-test-auc:0.8395506+0.00511380017599\tcv-train-auc:0.8704588+0.000550580929564\n",
      "[167]\tcv-test-auc:0.839551+0.00511258983295\tcv-train-auc:0.8705928+0.000489008547983\n",
      "[168]\tcv-test-auc:0.8395656+0.00504581773749\tcv-train-auc:0.8707358+0.00051449019427\n",
      "[169]\tcv-test-auc:0.839549+0.00504232144949\tcv-train-auc:0.870859+0.000521412696432\n",
      "[170]\tcv-test-auc:0.839522+0.00505057481877\tcv-train-auc:0.8709686+0.000510195099937\n",
      "[171]\tcv-test-auc:0.83959+0.00504255538393\tcv-train-auc:0.8711014+0.00050677908402\n",
      "[172]\tcv-test-auc:0.8395732+0.00500979813565\tcv-train-auc:0.871237+0.000493635898208\n",
      "[173]\tcv-test-auc:0.8395946+0.00501243296614\tcv-train-auc:0.8713652+0.000500941274003\n",
      "[174]\tcv-test-auc:0.839594+0.00504940309344\tcv-train-auc:0.871519+0.000522895018144\n",
      "[175]\tcv-test-auc:0.8395888+0.00505477043593\tcv-train-auc:0.8716728+0.000508853377703\n",
      "[176]\tcv-test-auc:0.8396088+0.00498291297937\tcv-train-auc:0.871805+0.00047664368243\n",
      "[177]\tcv-test-auc:0.8396806+0.00493593563977\tcv-train-auc:0.8719388+0.000510388244379\n",
      "[178]\tcv-test-auc:0.839699+0.00489483176422\tcv-train-auc:0.872077+0.000520476320307\n",
      "[179]\tcv-test-auc:0.8397432+0.00489534118934\tcv-train-auc:0.8721756+0.000540260529745\n",
      "[180]\tcv-test-auc:0.8397624+0.00486143742529\tcv-train-auc:0.8723008+0.000546119913572\n",
      "[181]\tcv-test-auc:0.8397952+0.00487705572656\tcv-train-auc:0.8724516+0.00061625858209\n",
      "[182]\tcv-test-auc:0.8398402+0.0048870767295\tcv-train-auc:0.8725904+0.000640200156201\n",
      "[183]\tcv-test-auc:0.8398366+0.00487086582037\tcv-train-auc:0.8727744+0.000655086742348\n",
      "[184]\tcv-test-auc:0.8398726+0.00488092993599\tcv-train-auc:0.8728788+0.000674488665583\n",
      "[185]\tcv-test-auc:0.839874+0.00488200823432\tcv-train-auc:0.8730082+0.000694180207151\n",
      "[186]\tcv-test-auc:0.8398532+0.00486699128415\tcv-train-auc:0.8731428+0.000681160304187\n",
      "[187]\tcv-test-auc:0.8398594+0.00488742179886\tcv-train-auc:0.873262+0.000719690211133\n",
      "[188]\tcv-test-auc:0.8398732+0.00490302353247\tcv-train-auc:0.8734054+0.000684079702959\n",
      "[189]\tcv-test-auc:0.839879+0.00486111168356\tcv-train-auc:0.8735122+0.000654640786997\n",
      "[190]\tcv-test-auc:0.8397826+0.00487343002822\tcv-train-auc:0.8736206+0.000657948204648\n",
      "[191]\tcv-test-auc:0.839877+0.00485439038397\tcv-train-auc:0.8737752+0.00067453077024\n",
      "[192]\tcv-test-auc:0.8398756+0.00486121978931\tcv-train-auc:0.873921+0.000625374128023\n",
      "[193]\tcv-test-auc:0.8398668+0.00484854433413\tcv-train-auc:0.8740308+0.000609869953351\n",
      "[194]\tcv-test-auc:0.8398782+0.00484257288639\tcv-train-auc:0.8741616+0.00060285407853\n",
      "[195]\tcv-test-auc:0.8398856+0.00483900112007\tcv-train-auc:0.8742462+0.000602418260015\n",
      "[196]\tcv-test-auc:0.8398854+0.00483818795005\tcv-train-auc:0.8743816+0.000541658785584\n",
      "[197]\tcv-test-auc:0.8398946+0.00484343781213\tcv-train-auc:0.8745122+0.000521245968809\n",
      "[198]\tcv-test-auc:0.8398832+0.00484022790373\tcv-train-auc:0.8746548+0.0005378506856\n",
      "[199]\tcv-test-auc:0.839904+0.00482468535762\tcv-train-auc:0.8747388+0.000524258485864\n",
      "[200]\tcv-test-auc:0.839903+0.00479448912816\tcv-train-auc:0.8748758+0.000505950748591\n",
      "[201]\tcv-test-auc:0.8399102+0.00479170397249\tcv-train-auc:0.8749946+0.000513134134511\n",
      "[202]\tcv-test-auc:0.8399484+0.00477072454036\tcv-train-auc:0.875107+0.000499687902595\n",
      "[203]\tcv-test-auc:0.8399746+0.00476566564501\tcv-train-auc:0.8752014+0.000490241817882\n",
      "[204]\tcv-test-auc:0.83998+0.00478462775982\tcv-train-auc:0.8753278+0.000467462683003\n",
      "[205]\tcv-test-auc:0.8400174+0.00475910590763\tcv-train-auc:0.8754608+0.000485229182964\n",
      "[206]\tcv-test-auc:0.8400412+0.00477998453554\tcv-train-auc:0.8755388+0.000499217547769\n",
      "[207]\tcv-test-auc:0.8400646+0.0047835419764\tcv-train-auc:0.8756172+0.000515848194724\n",
      "[208]\tcv-test-auc:0.8400576+0.00477693816581\tcv-train-auc:0.8757092+0.000551459300402\n",
      "[209]\tcv-test-auc:0.8400428+0.00479748277329\tcv-train-auc:0.8758432+0.000559882987775\n",
      "[210]\tcv-test-auc:0.8400382+0.00485810281489\tcv-train-auc:0.8759544+0.00054659989023\n",
      "[211]\tcv-test-auc:0.8400122+0.00490919917706\tcv-train-auc:0.876016+0.000548001824814\n",
      "[212]\tcv-test-auc:0.8399686+0.00492424802787\tcv-train-auc:0.8760898+0.000544856458161\n",
      "[213]\tcv-test-auc:0.8398832+0.00494890074259\tcv-train-auc:0.8762266+0.000575083854755\n",
      "[214]\tcv-test-auc:0.8398592+0.00492220525375\tcv-train-auc:0.8763188+0.000577208246649\n",
      "[215]\tcv-test-auc:0.8398762+0.00493567079129\tcv-train-auc:0.8764596+0.000548529160574\n",
      "[216]\tcv-test-auc:0.8398484+0.00495731752463\tcv-train-auc:0.8765576+0.000556075390572\n",
      "[217]\tcv-test-auc:0.8398604+0.0049490384359\tcv-train-auc:0.876691+0.000542374409426\n",
      "[218]\tcv-test-auc:0.8398746+0.00494593835789\tcv-train-auc:0.8768006+0.000518077445948\n",
      "[219]\tcv-test-auc:0.8398888+0.00496007449138\tcv-train-auc:0.8769008+0.000543365585955\n",
      "[220]\tcv-test-auc:0.8398908+0.00498444979511\tcv-train-auc:0.877005+0.000538883289776\n",
      "[221]\tcv-test-auc:0.8398924+0.00501159665576\tcv-train-auc:0.8771+0.000524431501724\n",
      "[222]\tcv-test-auc:0.8399056+0.00501351599579\tcv-train-auc:0.8771896+0.000555257994089\n",
      "[223]\tcv-test-auc:0.8398534+0.00501551343733\tcv-train-auc:0.8772746+0.000525712697203\n",
      "[224]\tcv-test-auc:0.8398118+0.00501880142664\tcv-train-auc:0.8773474+0.000521522616959\n",
      "[225]\tcv-test-auc:0.8397694+0.00500609686682\tcv-train-auc:0.8774692+0.000491285416026\n",
      "[226]\tcv-test-auc:0.8397748+0.00499387522471\tcv-train-auc:0.8775544+0.00046308901952\n",
      "[227]\tcv-test-auc:0.8397232+0.00497857985373\tcv-train-auc:0.8777218+0.000450787932403\n",
      "[228]\tcv-test-auc:0.8397052+0.00496232902577\tcv-train-auc:0.8778362+0.000490301295124\n",
      "[229]\tcv-test-auc:0.839714+0.00496552502763\tcv-train-auc:0.8779364+0.000523441152375\n",
      "[230]\tcv-test-auc:0.8397468+0.00494663576181\tcv-train-auc:0.878066+0.000468719532343\n",
      "[231]\tcv-test-auc:0.8397586+0.00491215954953\tcv-train-auc:0.878176+0.000409886325705\n",
      "[232]\tcv-test-auc:0.8397816+0.00492860692691\tcv-train-auc:0.8782814+0.000418013683987\n",
      "[233]\tcv-test-auc:0.8397924+0.00491225327523\tcv-train-auc:0.8783568+0.000440477195777\n",
      "[234]\tcv-test-auc:0.8397766+0.00488611881149\tcv-train-auc:0.8784316+0.000438319791933\n",
      "[235]\tcv-test-auc:0.8397654+0.00489176600422\tcv-train-auc:0.8785294+0.000423704425278\n",
      "[236]\tcv-test-auc:0.8397792+0.00488504621882\tcv-train-auc:0.8786438+0.000419002338896\n",
      "[237]\tcv-test-auc:0.8397882+0.00488769996624\tcv-train-auc:0.8787616+0.000397269983764\n",
      "[238]\tcv-test-auc:0.8397886+0.00490912124927\tcv-train-auc:0.878866+0.00038535645836\n",
      "[239]\tcv-test-auc:0.8398076+0.00488985147423\tcv-train-auc:0.8789728+0.00039599969697\n",
      "[240]\tcv-test-auc:0.8398096+0.00489677194078\tcv-train-auc:0.8790542+0.000406037141158\n",
      "[241]\tcv-test-auc:0.839829+0.00487070376845\tcv-train-auc:0.8791202+0.000386536104394\n",
      "[242]\tcv-test-auc:0.8398078+0.00486359638128\tcv-train-auc:0.8792614+0.000395918981611\n",
      "[243]\tcv-test-auc:0.8397986+0.00487574431651\tcv-train-auc:0.879354+0.000376433261017\n",
      "[244]\tcv-test-auc:0.8397956+0.00487361166282\tcv-train-auc:0.879461+0.000358626825544\n",
      "[245]\tcv-test-auc:0.839783+0.00490243119279\tcv-train-auc:0.8795548+0.000335816259285\n",
      "[246]\tcv-test-auc:0.8397324+0.00491890189372\tcv-train-auc:0.8796582+0.000354379119024\n",
      "[247]\tcv-test-auc:0.8397452+0.0049086995182\tcv-train-auc:0.8796982+0.000353886083366\n",
      "[248]\tcv-test-auc:0.8397432+0.0048918605622\tcv-train-auc:0.8798276+0.000383832046604\n",
      "[249]\tcv-test-auc:0.839743+0.00486421825168\tcv-train-auc:0.8799106+0.000392061525784\n",
      "[250]\tcv-test-auc:0.8397396+0.00484919480326\tcv-train-auc:0.8799666+0.000368871576568\n",
      "[251]\tcv-test-auc:0.8397454+0.0048661179846\tcv-train-auc:0.8800742+0.000407070215073\n",
      "[252]\tcv-test-auc:0.839751+0.00483937247998\tcv-train-auc:0.880179+0.000407456991595\n",
      "[253]\tcv-test-auc:0.8397522+0.00485225627518\tcv-train-auc:0.8802756+0.000402473154384\n",
      "[254]\tcv-test-auc:0.8397708+0.0048629206615\tcv-train-auc:0.8803812+0.000425973426401\n",
      "[255]\tcv-test-auc:0.8397738+0.00483409190645\tcv-train-auc:0.8804782+0.000402460631615\n",
      "[256]\tcv-test-auc:0.839741+0.00488759593256\tcv-train-auc:0.8805854+0.00037568529383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0         0.766888      0.044776        0.776455       0.042135\n",
      "1         0.802528      0.013580        0.814179       0.004542\n",
      "2         0.807856      0.017067        0.819856       0.007403\n",
      "3         0.810158      0.016078        0.821942       0.008403\n",
      "4         0.812786      0.013484        0.824890       0.005481\n",
      "5         0.812525      0.013792        0.824738       0.006831\n",
      "6         0.815006      0.011898        0.826525       0.006826\n",
      "7         0.818203      0.010833        0.830798       0.004398\n",
      "8         0.818047      0.010890        0.831399       0.003420\n",
      "9         0.819028      0.010496        0.832637       0.002667\n",
      "10        0.820345      0.009628        0.834006       0.002221\n",
      "11        0.821593      0.009287        0.835550       0.001886\n",
      "12        0.821010      0.010944        0.835250       0.002286\n",
      "13        0.822265      0.010516        0.836431       0.001922\n",
      "14        0.823030      0.010157        0.837003       0.001570\n",
      "15        0.824278      0.009197        0.838342       0.001411\n",
      "16        0.824733      0.008995        0.839051       0.000860\n",
      "17        0.824747      0.008431        0.839208       0.001605\n",
      "18        0.825177      0.008118        0.839989       0.002040\n",
      "19        0.825537      0.008421        0.840297       0.001856\n",
      "20        0.825599      0.008088        0.840527       0.002689\n",
      "21        0.825598      0.008080        0.840729       0.001836\n",
      "22        0.825010      0.008563        0.840329       0.002407\n",
      "23        0.825170      0.008077        0.840592       0.001839\n",
      "24        0.825982      0.008125        0.841494       0.001838\n",
      "25        0.825874      0.007588        0.841300       0.002068\n",
      "26        0.825794      0.007350        0.841493       0.001727\n",
      "27        0.825907      0.006898        0.841627       0.001611\n",
      "28        0.826599      0.006796        0.842557       0.001965\n",
      "29        0.826958      0.007116        0.842897       0.001954\n",
      "..             ...           ...             ...            ...\n",
      "178       0.839699      0.004895        0.872077       0.000520\n",
      "179       0.839743      0.004895        0.872176       0.000540\n",
      "180       0.839762      0.004861        0.872301       0.000546\n",
      "181       0.839795      0.004877        0.872452       0.000616\n",
      "182       0.839840      0.004887        0.872590       0.000640\n",
      "183       0.839837      0.004871        0.872774       0.000655\n",
      "184       0.839873      0.004881        0.872879       0.000674\n",
      "185       0.839874      0.004882        0.873008       0.000694\n",
      "186       0.839853      0.004867        0.873143       0.000681\n",
      "187       0.839859      0.004887        0.873262       0.000720\n",
      "188       0.839873      0.004903        0.873405       0.000684\n",
      "189       0.839879      0.004861        0.873512       0.000655\n",
      "190       0.839783      0.004873        0.873621       0.000658\n",
      "191       0.839877      0.004854        0.873775       0.000675\n",
      "192       0.839876      0.004861        0.873921       0.000625\n",
      "193       0.839867      0.004849        0.874031       0.000610\n",
      "194       0.839878      0.004843        0.874162       0.000603\n",
      "195       0.839886      0.004839        0.874246       0.000602\n",
      "196       0.839885      0.004838        0.874382       0.000542\n",
      "197       0.839895      0.004843        0.874512       0.000521\n",
      "198       0.839883      0.004840        0.874655       0.000538\n",
      "199       0.839904      0.004825        0.874739       0.000524\n",
      "200       0.839903      0.004794        0.874876       0.000506\n",
      "201       0.839910      0.004792        0.874995       0.000513\n",
      "202       0.839948      0.004771        0.875107       0.000500\n",
      "203       0.839975      0.004766        0.875201       0.000490\n",
      "204       0.839980      0.004785        0.875328       0.000467\n",
      "205       0.840017      0.004759        0.875461       0.000485\n",
      "206       0.840041      0.004780        0.875539       0.000499\n",
      "207       0.840065      0.004784        0.875617       0.000516\n",
      "\n",
      "[208 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9608\n",
      "AUC Score (Train): 0.869309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[257]\tcv-test-auc:0.8397236+0.00490025805851\tcv-train-auc:0.8806558+0.00038889967858\n",
      "Stopping. Best iteration: 207\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(missing=np.nan,\n",
    " learning_rate =0.03,\n",
    " n_estimators=10000,\n",
    " max_depth=5,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=1e-05,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train, y_train,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall AUC:', 0.86930937094208349)\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "print('Overall AUC:', roc_auc_score(y_train, xgb3.predict_proba(X_train)[:,1]))\n",
    "\n",
    "# predicting\n",
    "y_pred= xgb3.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"submission_xgb.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
