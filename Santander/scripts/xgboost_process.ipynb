{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv\n",
      "train.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "# Input data files are available in the \"../data/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../data\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See random_forest_var_imp.ipynb\n",
    "imp_vars = ['var38',\n",
    " 'var15',\n",
    " 'saldo_medio_var5_ult3',\n",
    " 'saldo_medio_var5_hace3',\n",
    " 'num_var45_ult3',\n",
    " 'saldo_var30',\n",
    " 'saldo_medio_var5_hace2',\n",
    " 'num_var45_hace3',\n",
    " 'saldo_var42',\n",
    " 'num_var45_hace2',\n",
    " 'num_var22_ult3',\n",
    " 'saldo_medio_var5_ult1',\n",
    " 'saldo_var5',\n",
    " 'num_var45_ult1',\n",
    " 'num_var22_hace3',\n",
    " 'num_var22_hace2',\n",
    " 'num_med_var45_ult3',\n",
    " 'var36',\n",
    " 'num_var22_ult1',\n",
    " 'num_meses_var39_vig_ult3',\n",
    " 'num_meses_var5_ult3',\n",
    " 'num_med_var22_ult3',\n",
    " 'imp_op_var41_ult1',\n",
    " 'imp_op_var39_ult1',\n",
    " 'imp_op_var41_comer_ult3',\n",
    " 'imp_op_var39_comer_ult3',\n",
    " 'num_var35',\n",
    " 'imp_trans_var37_ult1',\n",
    " 'num_var4',\n",
    " 'imp_op_var41_efect_ult3',\n",
    " 'imp_op_var39_efect_ult3',\n",
    " 'imp_op_var41_comer_ult1',\n",
    " 'imp_op_var39_comer_ult1',\n",
    " 'var3',\n",
    " 'saldo_var37',\n",
    " 'num_op_var41_ult3',\n",
    " 'num_op_var39_ult3',\n",
    " 'imp_op_var39_efect_ult1',\n",
    " 'imp_op_var41_efect_ult1',\n",
    " 'imp_ent_var16_ult1',\n",
    " 'num_op_var41_comer_ult3',\n",
    " 'num_op_var39_comer_ult3',\n",
    " 'num_op_var41_ult1',\n",
    " 'num_op_var39_hace2',\n",
    " 'num_var30',\n",
    " 'num_op_var41_hace2',\n",
    " 'num_op_var39_ult1',\n",
    " 'imp_var43_emit_ult1',\n",
    " 'num_op_var41_efect_ult3',\n",
    " 'num_op_var39_efect_ult3',\n",
    " 'num_op_var39_comer_ult1',\n",
    " 'num_var43_recib_ult1',\n",
    " 'num_op_var41_comer_ult1',\n",
    " 'ind_var30',\n",
    " 'saldo_medio_var8_ult3',\n",
    " 'num_var43_emit_ult1',\n",
    " 'saldo_var8',\n",
    " 'num_var42',\n",
    " 'num_var41_0',\n",
    " 'num_var39_0',\n",
    " 'num_var37_0',\n",
    " 'num_ent_var16_ult1',\n",
    " 'saldo_medio_var8_ult1',\n",
    " 'num_op_var41_efect_ult1',\n",
    " 'num_var37_med_ult2',\n",
    " 'num_op_var39_efect_ult1',\n",
    " 'num_var5',\n",
    " 'num_var30_0',\n",
    " 'ind_var43_recib_ult1',\n",
    " 'num_var5_0',\n",
    " 'ind_var5',\n",
    " 'saldo_var26',\n",
    " 'saldo_var25',\n",
    " 'num_var42_0',\n",
    " 'ind_var43_emit_ult1',\n",
    " 'saldo_medio_var8_hace2',\n",
    " 'num_var8_0',\n",
    " 'ind_var41_0',\n",
    " 'ind_var39_0',\n",
    " 'ind_var8_0',\n",
    " 'ind_var37_cte',\n",
    " 'ind_var9_ult1',\n",
    " 'ind_var9_cte_ult1',\n",
    " 'ind_var37_0',\n",
    " 'ind_var10cte_ult1',\n",
    " 'saldo_var12',\n",
    " 'saldo_medio_var12_ult1',\n",
    " 'num_trasp_var11_ult1',\n",
    " 'ind_var5_0',\n",
    " 'ind_var10_ult1',\n",
    " 'saldo_var13',\n",
    " 'saldo_medio_var13_corto_ult3',\n",
    " 'saldo_medio_var12_ult3',\n",
    " 'num_var12_0',\n",
    " 'num_op_var41_hace3',\n",
    " 'num_op_var39_hace3',\n",
    " 'num_meses_var8_ult3',\n",
    " 'saldo_var24',\n",
    " 'saldo_medio_var8_hace3',\n",
    " 'saldo_medio_var13_corto_hace2',\n",
    " 'saldo_medio_var12_hace2',\n",
    " 'num_var26_0',\n",
    " 'num_var25_0',\n",
    " 'ind_var12_0',\n",
    " 'var21',\n",
    " 'saldo_var13_corto',\n",
    " 'saldo_medio_var13_corto_ult1',\n",
    " 'num_var24_0',\n",
    " 'ind_var26_cte',\n",
    " 'ind_var24_0',\n",
    " 'imp_var7_recib_ult1',\n",
    " 'imp_op_var40_efect_ult1',\n",
    " 'num_var7_recib_ult1',\n",
    " 'num_var40_0',\n",
    " 'num_var1_0',\n",
    " 'num_var14_0',\n",
    " 'num_var13_0',\n",
    " 'num_sal_var16_ult1',\n",
    " 'num_meses_var12_ult3',\n",
    " 'ind_var26_0',\n",
    " 'ind_var25_cte',\n",
    " 'ind_var25_0',\n",
    " 'imp_sal_var16_ult1',\n",
    " 'saldo_var40',\n",
    " 'saldo_var1',\n",
    " 'saldo_medio_var12_hace3',\n",
    " 'num_var8',\n",
    " 'num_var13',\n",
    " 'num_var12',\n",
    " 'num_op_var40_efect_ult3',\n",
    " 'num_op_var40_efect_ult1',\n",
    " 'num_op_var40_comer_ult3',\n",
    " 'num_meses_var13_corto_ult3',\n",
    " 'ind_var8',\n",
    " 'ind_var7_recib_ult1',\n",
    " 'ind_var40_0',\n",
    " 'ind_var32_cte',\n",
    " 'ind_var30_0',\n",
    " 'ind_var1_0',\n",
    " 'ind_var14_0',\n",
    " 'ind_var13_0',\n",
    " 'ind_var13',\n",
    " 'ind_var12',\n",
    " 'imp_op_var40_efect_ult3',\n",
    " 'saldo_var44',\n",
    " 'saldo_var32',\n",
    " 'saldo_var31',\n",
    " 'saldo_var14',\n",
    " 'saldo_var13_largo',\n",
    " 'saldo_medio_var17_ult3',\n",
    " 'saldo_medio_var13_corto_hace3',\n",
    " 'num_var40',\n",
    " 'num_var32_0',\n",
    " 'num_var31_0',\n",
    " 'num_var31',\n",
    " 'num_var24',\n",
    " 'num_var14',\n",
    " 'num_var13_corto_0',\n",
    " 'num_var13_corto',\n",
    " 'num_var1',\n",
    " 'num_reemb_var17_ult1',\n",
    " 'num_op_var40_ult3',\n",
    " 'num_op_var40_ult1',\n",
    " 'num_op_var40_comer_ult1',\n",
    " 'num_aport_var13_hace3',\n",
    " 'ind_var40',\n",
    " 'ind_var24',\n",
    " 'ind_var19',\n",
    " 'ind_var14',\n",
    " 'ind_var13_corto_0',\n",
    " 'ind_var13_corto',\n",
    " 'ind_var1',\n",
    " 'imp_reemb_var17_ult1',\n",
    " 'imp_op_var40_ult1',\n",
    " 'imp_op_var40_comer_ult3',\n",
    " 'imp_op_var40_comer_ult1',\n",
    " 'imp_compra_var44_ult1',\n",
    " 'imp_aport_var13_ult1',\n",
    " 'imp_aport_var13_hace3',\n",
    " 'delta_num_aport_var13_1y3',\n",
    " 'delta_imp_aport_var13_1y3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Any results you write to the current directory are saved as output.\n",
    "# load data\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# remove constant columns\n",
    "remove = []\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].std() == 0:\n",
    "        remove.append(col)\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "# remove duplicated columns\n",
    "remove = []\n",
    "c = df_train.columns\n",
    "for i in range(len(c)-1):\n",
    "    v = df_train[c[i]].values\n",
    "    for j in range(i+1,len(c)):\n",
    "        if np.array_equal(v,df_train[c[j]].values):\n",
    "            remove.append(c[j])\n",
    "\n",
    "df_train.drop(remove, axis=1, inplace=True)\n",
    "df_test.drop(remove, axis=1, inplace=True)\n",
    "\n",
    "y_train = df_train['TARGET'].values\n",
    "X_train = df_train.drop(['ID','TARGET'], axis=1)\n",
    "X_train = X_train[imp_vars].values\n",
    "\n",
    "id_test = df_test['ID']\n",
    "X_test = df_test.drop(['ID'], axis=1)\n",
    "X_test = X_test[imp_vars].values\n",
    "\n",
    "# length of dataset\n",
    "len_train = len(X_train)\n",
    "len_test  = len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good XGBoost Function From Blog Analytics Vidhya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "def modelfit(alg, X_train, y_train, useTrainCV=True, cv_folds=5, early_stopping_rounds=50, show_progress=False):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics=['auc'], early_stopping_rounds=early_stopping_rounds, show_progress=show_progress)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print cvresult\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(X_train, y_train,eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(X_train)\n",
    "    dtrain_predprob = alg.predict_proba(X_train)[:,1]\n",
    "        \n",
    "    #Print model report:\n",
    "    print \"\\nModel Report\"\n",
    "    print \"Accuracy : %.4g\" % metrics.accuracy_score(y_train, dtrain_predictions)\n",
    "    print \"AUC Score (Train): %f\" % metrics.roc_auc_score(y_train, dtrain_predprob)\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start With some params and tune n_estimators first of all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "Stopping. Best iteration: 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.763823      0.047972        0.774362       0.046936\n",
      "1        0.803734      0.013635        0.815649       0.007018\n",
      "2        0.808262      0.016565        0.820947       0.006191\n",
      "3        0.812470      0.018497        0.824765       0.011232\n",
      "4        0.814057      0.012854        0.826689       0.004827\n",
      "5        0.815386      0.009768        0.829109       0.005731\n",
      "6        0.818147      0.009034        0.831863       0.007940\n",
      "7        0.821003      0.008650        0.835261       0.005342\n",
      "8        0.820649      0.009144        0.836147       0.003935\n",
      "9        0.822796      0.008348        0.838670       0.002975\n",
      "10       0.825051      0.007301        0.841057       0.002329\n",
      "11       0.826349      0.007184        0.842850       0.001943\n",
      "12       0.826292      0.007753        0.843005       0.001186\n",
      "13       0.827659      0.007253        0.844759       0.001380\n",
      "14       0.828019      0.007362        0.845520       0.002088\n",
      "15       0.828758      0.006758        0.846697       0.001921\n",
      "16       0.829553      0.007054        0.847618       0.001618\n",
      "17       0.829548      0.006975        0.848169       0.002188\n",
      "18       0.830060      0.006314        0.849066       0.002906\n",
      "19       0.830888      0.005929        0.850188       0.001890\n",
      "20       0.830983      0.006000        0.851070       0.002392\n",
      "21       0.831835      0.006089        0.851857       0.001912\n",
      "22       0.831737      0.006272        0.852305       0.002073\n",
      "23       0.832169      0.006257        0.853063       0.001346\n",
      "24       0.832928      0.006320        0.854171       0.001200\n",
      "25       0.832667      0.005986        0.854279       0.001372\n",
      "26       0.832273      0.005840        0.854840       0.001156\n",
      "27       0.832819      0.005029        0.855507       0.001458\n",
      "28       0.833669      0.005267        0.856888       0.000947\n",
      "29       0.834039      0.005524        0.857546       0.000868\n",
      "..            ...           ...             ...            ...\n",
      "47       0.838189      0.005211        0.870084       0.000935\n",
      "48       0.838342      0.005045        0.870685       0.000972\n",
      "49       0.838411      0.005074        0.871110       0.000913\n",
      "50       0.838451      0.004968        0.871487       0.000966\n",
      "51       0.838426      0.004871        0.871925       0.000924\n",
      "52       0.838463      0.004737        0.872521       0.000912\n",
      "53       0.838540      0.004850        0.873084       0.000796\n",
      "54       0.838399      0.004865        0.873596       0.000713\n",
      "55       0.838505      0.004686        0.874045       0.000735\n",
      "56       0.838782      0.004682        0.874468       0.000749\n",
      "57       0.838714      0.004708        0.875049       0.000739\n",
      "58       0.838847      0.004670        0.875468       0.000692\n",
      "59       0.838856      0.004820        0.875891       0.000731\n",
      "60       0.838882      0.004821        0.876402       0.000804\n",
      "61       0.838970      0.004774        0.876806       0.000764\n",
      "62       0.838980      0.004812        0.877243       0.000985\n",
      "63       0.838978      0.004821        0.877593       0.000988\n",
      "64       0.838995      0.004883        0.877875       0.000969\n",
      "65       0.838832      0.004973        0.878343       0.001074\n",
      "66       0.838754      0.005067        0.878825       0.001124\n",
      "67       0.838737      0.004973        0.879249       0.001104\n",
      "68       0.838730      0.004919        0.879640       0.001215\n",
      "69       0.838861      0.004801        0.880034       0.001209\n",
      "70       0.838932      0.004587        0.880592       0.001163\n",
      "71       0.839002      0.004555        0.880995       0.001088\n",
      "72       0.839077      0.004587        0.881339       0.001149\n",
      "73       0.839163      0.004485        0.881738       0.001148\n",
      "74       0.839254      0.004646        0.882237       0.001253\n",
      "75       0.839262      0.004601        0.882728       0.001456\n",
      "76       0.839292      0.004628        0.883083       0.001372\n",
      "\n",
      "[77 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9611\n",
      "AUC Score (Train): 0.875625\n"
     ]
    }
   ],
   "source": [
    "modelfit(xgb1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1.n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Tune Max_Depth and min_Child_Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to new file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   2 jobs       | elapsed:   22.6s\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   1 jobs       | elapsed:   23.1s\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   3 jobs       | elapsed:   52.8s\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   4 jobs       | elapsed:   53.6s\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   5 jobs       | elapsed:  1.3min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   6 jobs       | elapsed:  1.3min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   7 jobs       | elapsed:  1.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   8 jobs       | elapsed:  1.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done   9 jobs       | elapsed:  2.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  10 jobs       | elapsed:  2.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  11 jobs       | elapsed:  2.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  12 jobs       | elapsed:  2.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  13 jobs       | elapsed:  3.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  14 jobs       | elapsed:  3.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  15 jobs       | elapsed:  3.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  16 jobs       | elapsed:  3.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  17 jobs       | elapsed:  4.1min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  18 jobs       | elapsed:  4.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  19 jobs       | elapsed:  4.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  20 jobs       | elapsed:  5.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  21 jobs       | elapsed:  5.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  22 jobs       | elapsed:  5.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  23 jobs       | elapsed:  6.1min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  24 jobs       | elapsed:  6.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  25 jobs       | elapsed:  6.8min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  26 jobs       | elapsed:  7.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  27 jobs       | elapsed:  7.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  28 jobs       | elapsed:  7.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  29 jobs       | elapsed:  8.1min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  30 jobs       | elapsed:  8.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  31 jobs       | elapsed:  9.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  32 jobs       | elapsed:  9.3min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  33 jobs       | elapsed:  9.9min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  34 jobs       | elapsed: 10.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  35 jobs       | elapsed: 10.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  36 jobs       | elapsed: 11.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  37 jobs       | elapsed: 11.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  38 jobs       | elapsed: 11.9min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  39 jobs       | elapsed: 12.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  40 jobs       | elapsed: 12.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  41 jobs       | elapsed: 13.3min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  42 jobs       | elapsed: 13.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  43 jobs       | elapsed: 14.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  44 jobs       | elapsed: 14.5min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  45 jobs       | elapsed: 15.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  46 jobs       | elapsed: 15.8min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  47 jobs       | elapsed: 16.4min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  48 jobs       | elapsed: 17.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  49 jobs       | elapsed: 17.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  50 jobs       | elapsed: 18.1min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  51 jobs       | elapsed: 18.8min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  52 jobs       | elapsed: 19.3min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  53 jobs       | elapsed: 20.0min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  54 jobs       | elapsed: 20.6min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60815,), dtype=int64).\n",
      "Pickling array (shape=(15205,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  55 jobs       | elapsed: 21.2min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60816,), dtype=int64).\n",
      "Pickling array (shape=(15204,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  56 jobs       | elapsed: 21.8min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  57 jobs       | elapsed: 22.7min\n",
      "Memmaping (shape=(76020, 181), dtype=float64) to old file /var/folders/rf/x5jhln3158n6pyl8jpk3_psc0000gn/T/joblib_memmaping_pool_28905_4357462736/28905-4432261072-4434406816-0.pkl\n",
      "Pickling array (shape=(76020,), dtype=int64).\n",
      "Pickling array (shape=(60817,), dtype=int64).\n",
      "Pickling array (shape=(15203,), dtype=int64).\n",
      "[Parallel(n_jobs=2)]: Done  58 out of  60 | elapsed: 23.3min remaining:   48.2s\n",
      "[Parallel(n_jobs=2)]: Done  59 out of  60 | elapsed: 24.2min remaining:   24.6s\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed: 24.6min finished\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.834436 -  22.7s[CV] ........ max_depth=3, min_child_weight=1, score=0.825260 -  22.3s\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=1 .................................\n",
      "[CV] max_depth=3, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=1, score=0.852481 -  30.4s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.839725 -  30.1s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=3, score=0.834791 -  26.9s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=1, score=0.835136 -  26.7s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=3, score=0.840869 -  23.3s[CV] max_depth=3, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=3, min_child_weight=3, score=0.826165 -  23.6s[CV] ........ max_depth=3, min_child_weight=3, score=0.833737 -  26.4s\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=3 .................................[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.826788 -  24.4s[CV] ........ max_depth=3, min_child_weight=3, score=0.852933 -  26.4s\n",
      "\n",
      "[CV] max_depth=3, min_child_weight=5 .................................\n",
      "[CV] max_depth=3, min_child_weight=5 .................................[CV] ........ max_depth=3, min_child_weight=5, score=0.853204 -  26.4s\n",
      "\n",
      "[CV] ........ max_depth=3, min_child_weight=5, score=0.834082 -  24.4s[CV] max_depth=5, min_child_weight=1 .................................\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=1, score=0.835401 -  41.4s[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=5, score=0.841704 -  26.4s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=1, score=0.844064 -  39.8s[CV] max_depth=3, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=1 .................................[CV] ........ max_depth=3, min_child_weight=5, score=0.835342 -  24.3s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=1, score=0.836593 -  36.7s[CV] max_depth=5, min_child_weight=1 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=3 .................................[CV] ........ max_depth=5, min_child_weight=1, score=0.828123 -  41.1s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=3, score=0.827861 -  40.0s[CV] max_depth=5, min_child_weight=1 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=3 .................................[CV] ........ max_depth=5, min_child_weight=1, score=0.854419 -  37.4s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=3, score=0.853608 -  42.3s[CV] max_depth=5, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=5 .................................[CV] ........ max_depth=5, min_child_weight=3, score=0.837208 -  39.3s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.836715 -  40.3s[CV] max_depth=5, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=5 .................................[CV] ........ max_depth=5, min_child_weight=3, score=0.845048 -  40.7s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.846515 -  41.1s[CV] max_depth=5, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=5, min_child_weight=5 .................................[CV] ........ max_depth=5, min_child_weight=3, score=0.839003 -  41.4s\n",
      "\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.839220 -  39.3s[CV] max_depth=5, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=1 .................................[CV] ........ max_depth=5, min_child_weight=5, score=0.826906 -  41.1s\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=1, score=0.826462 -  55.0s[CV] max_depth=5, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=1 .................................\n",
      "[CV] ........ max_depth=5, min_child_weight=5, score=0.853223 -  37.9s[CV] ........ max_depth=7, min_child_weight=1, score=0.854035 -  51.7s\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=1 .................................[CV] max_depth=7, min_child_weight=3 .................................\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=3, score=0.835163 -  50.2s[CV] ........ max_depth=7, min_child_weight=1, score=0.833150 -  57.1s\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=3 .................................\n",
      "[CV] max_depth=7, min_child_weight=1 .................................[CV] ........ max_depth=7, min_child_weight=3, score=0.843777 -  51.3s\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=1, score=0.842729 -  51.4s[CV] max_depth=7, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=1 .................................[CV] ........ max_depth=7, min_child_weight=3, score=0.836137 -  51.9s\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=1, score=0.836203 -  51.2s[CV] max_depth=7, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=3 .................................[CV] ........ max_depth=7, min_child_weight=5, score=0.827336 -  54.2s\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=3, score=0.828463 -  50.7s[CV] max_depth=7, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=3 .................................[CV] ........ max_depth=7, min_child_weight=5, score=0.853169 -  55.0s\n",
      "\n",
      "[CV] ........ max_depth=7, min_child_weight=3, score=0.853581 -  51.2s[CV] max_depth=9, min_child_weight=1 .................................\n",
      "\n",
      "[CV] max_depth=7, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=9, min_child_weight=1, score=0.830098 - 1.2min[CV] ........ max_depth=7, min_child_weight=5, score=0.834145 -  54.3s\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=1 .................................[CV] max_depth=7, min_child_weight=5 .................................\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=1, score=0.838528 - 1.2min[CV] ........ max_depth=7, min_child_weight=5, score=0.843904 -  54.1s\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=1 .................................[CV] max_depth=7, min_child_weight=5 .................................\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=1, score=0.834425 - 1.1min[CV] ........ max_depth=7, min_child_weight=5, score=0.838483 -  58.2s\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] max_depth=9, min_child_weight=1 .................................[CV] ........ max_depth=9, min_child_weight=3, score=0.826165 - 1.2min\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=1, score=0.824161 - 1.2min[CV] max_depth=9, min_child_weight=3 .................................\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=1 .................................[CV] ........ max_depth=9, min_child_weight=3, score=0.850572 - 1.3min\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=1, score=0.851584 - 1.2min[CV] max_depth=9, min_child_weight=5 .................................\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=3 .................................\n",
      "[CV] ........ max_depth=9, min_child_weight=5, score=0.832322 - 1.3min[CV] ........ max_depth=9, min_child_weight=3, score=0.829318 - 1.2min\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=5 .................................[CV] max_depth=9, min_child_weight=3 .................................\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=5, score=0.842803 - 1.4min[CV] ........ max_depth=9, min_child_weight=3, score=0.840996 - 1.2min\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=5 .................................[CV] max_depth=9, min_child_weight=3 .................................\n",
      "\n",
      "[CV] ........ max_depth=9, min_child_weight=5, score=0.836869 - 1.3min[CV] ........ max_depth=9, min_child_weight=3, score=0.837432 - 1.2min\n",
      "\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=9, min_child_weight=5, score=0.827495 - 1.5min\n",
      "[CV] max_depth=9, min_child_weight=5 .................................\n",
      "[CV] ........ max_depth=9, min_child_weight=5, score=0.852044 - 1.5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([mean: 0.83741, std: 0.00888, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.83770, std: 0.00894, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.83822, std: 0.00886, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.83972, std: 0.00892, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.84055, std: 0.00855, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.84052, std: 0.00893, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.83852, std: 0.00936, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.83942, std: 0.00858, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.83941, std: 0.00876, params: {'max_depth': 7, 'min_child_weight': 5},\n",
       "  mean: 0.83576, std: 0.00924, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.83690, std: 0.00868, params: {'max_depth': 9, 'min_child_weight': 3},\n",
       "  mean: 0.83831, std: 0.00853, params: {'max_depth': 9, 'min_child_weight': 5}],\n",
       " {'max_depth': 5, 'min_child_weight': 3},\n",
       " 0.84054568210341452)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {'max_depth':range(3,10,2),'min_child_weight':range(1,6,2)}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    "                                                  min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                                 objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    "                                                 param_grid = param_test1, scoring='roc_auc',n_jobs=2,iid=False, cv=5, \n",
    "                                                verbose=1000)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# searching for more optimum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83977, std: 0.00903, params: {'max_depth': 4, 'min_child_weight': 2},\n",
       "  mean: 0.83993, std: 0.00879, params: {'max_depth': 4, 'min_child_weight': 3},\n",
       "  mean: 0.83939, std: 0.00928, params: {'max_depth': 4, 'min_child_weight': 4},\n",
       "  mean: 0.83995, std: 0.00866, params: {'max_depth': 5, 'min_child_weight': 2},\n",
       "  mean: 0.84055, std: 0.00855, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.84012, std: 0.00910, params: {'max_depth': 5, 'min_child_weight': 4},\n",
       "  mean: 0.83859, std: 0.00946, params: {'max_depth': 6, 'min_child_weight': 2},\n",
       "  mean: 0.83917, std: 0.00824, params: {'max_depth': 6, 'min_child_weight': 3},\n",
       "  mean: 0.84022, std: 0.00877, params: {'max_depth': 6, 'min_child_weight': 4}],\n",
       " {'max_depth': 5, 'min_child_weight': 3},\n",
       " 0.84054568210341452)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[4,5,6],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#3. Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84055, std: 0.00855, params: {'gamma': 0.0},\n",
       "  mean: 0.84008, std: 0.00864, params: {'gamma': 0.1},\n",
       "  mean: 0.83951, std: 0.00919, params: {'gamma': 0.2},\n",
       "  mean: 0.83993, std: 0.00896, params: {'gamma': 0.3},\n",
       "  mean: 0.83969, std: 0.00898, params: {'gamma': 0.4}],\n",
       " {'gamma': 0.0},\n",
       " 0.84054568210341452)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test3 = {\n",
    " 'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This shows that our original value of gamma, i.e. 0 is the optimum one. Before proceeding, a good idea would be to re-calibrate the number of boosting rounds for the updated parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 75 rounds.\n",
      "Stopping. Best iteration: 74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.765040      0.047673        0.775638       0.045115\n",
      "1        0.804597      0.014327        0.815781       0.006890\n",
      "2        0.808440      0.017670        0.820612       0.007208\n",
      "3        0.812558      0.018928        0.824634       0.011052\n",
      "4        0.814372      0.014797        0.827276       0.005470\n",
      "5        0.815404      0.011688        0.829150       0.005696\n",
      "6        0.817367      0.010937        0.831988       0.007426\n",
      "7        0.820128      0.009868        0.835253       0.004960\n",
      "8        0.820196      0.010866        0.836122       0.003272\n",
      "9        0.822151      0.009638        0.838940       0.002889\n",
      "10       0.825126      0.007775        0.841629       0.002382\n",
      "11       0.826819      0.007185        0.843270       0.002261\n",
      "12       0.826916      0.008019        0.843412       0.000861\n",
      "13       0.828277      0.007417        0.845159       0.001112\n",
      "14       0.828938      0.007303        0.845927       0.001994\n",
      "15       0.829325      0.006818        0.846703       0.001967\n",
      "16       0.829786      0.006844        0.847678       0.001700\n",
      "17       0.830031      0.006510        0.848241       0.002252\n",
      "18       0.830202      0.006127        0.848822       0.003106\n",
      "19       0.830870      0.006210        0.849718       0.002104\n",
      "20       0.831096      0.006422        0.850561       0.002487\n",
      "21       0.831663      0.006387        0.851409       0.001806\n",
      "22       0.831568      0.006369        0.851733       0.002148\n",
      "23       0.831819      0.006111        0.852428       0.001571\n",
      "24       0.832626      0.006172        0.853386       0.001216\n",
      "25       0.832418      0.005947        0.853556       0.001459\n",
      "26       0.832210      0.005949        0.854093       0.001276\n",
      "27       0.832601      0.005269        0.854677       0.001570\n",
      "28       0.833611      0.005415        0.856010       0.001158\n",
      "29       0.833935      0.005820        0.856670       0.000860\n",
      "..            ...           ...             ...            ...\n",
      "45       0.838242      0.005601        0.866769       0.000750\n",
      "46       0.838212      0.005560        0.867346       0.000750\n",
      "47       0.838423      0.005357        0.867751       0.000797\n",
      "48       0.838640      0.005293        0.868220       0.000797\n",
      "49       0.838635      0.005265        0.868595       0.000752\n",
      "50       0.838811      0.005127        0.868924       0.000780\n",
      "51       0.838813      0.005000        0.869381       0.000849\n",
      "52       0.838777      0.004954        0.869902       0.000805\n",
      "53       0.838776      0.004913        0.870346       0.000639\n",
      "54       0.838855      0.004982        0.870689       0.000588\n",
      "55       0.839000      0.005024        0.871035       0.000632\n",
      "56       0.839068      0.005053        0.871358       0.000563\n",
      "57       0.838934      0.005106        0.871841       0.000482\n",
      "58       0.838967      0.005103        0.872179       0.000489\n",
      "59       0.838925      0.005155        0.872476       0.000496\n",
      "60       0.839025      0.005137        0.872947       0.000579\n",
      "61       0.839123      0.005071        0.873182       0.000634\n",
      "62       0.839098      0.005089        0.873580       0.000741\n",
      "63       0.839067      0.005050        0.873963       0.000698\n",
      "64       0.839113      0.005059        0.874251       0.000727\n",
      "65       0.839020      0.004943        0.874539       0.000721\n",
      "66       0.839052      0.004934        0.874893       0.000698\n",
      "67       0.839031      0.004796        0.875275       0.000828\n",
      "68       0.838909      0.004679        0.875593       0.000921\n",
      "69       0.838909      0.004552        0.875953       0.000803\n",
      "70       0.838946      0.004542        0.876451       0.000815\n",
      "71       0.839002      0.004548        0.876761       0.000859\n",
      "72       0.838994      0.004554        0.876959       0.000901\n",
      "73       0.839024      0.004607        0.877214       0.000901\n",
      "74       0.839205      0.004563        0.877718       0.001011\n",
      "\n",
      "[75 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9609\n",
      "AUC Score (Train): 0.871105\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, X_train, y_train,early_stopping_rounds=75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing awesome got. Will use the same no of trees as was using previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83992, std: 0.00870, params: {'subsample': 0.6, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84032, std: 0.00879, params: {'subsample': 0.7, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84023, std: 0.00912, params: {'subsample': 0.8, 'colsample_bytree': 0.6},\n",
       "  mean: 0.84030, std: 0.00912, params: {'subsample': 0.9, 'colsample_bytree': 0.6},\n",
       "  mean: 0.83913, std: 0.00859, params: {'subsample': 0.6, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83957, std: 0.00821, params: {'subsample': 0.7, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83974, std: 0.00924, params: {'subsample': 0.8, 'colsample_bytree': 0.7},\n",
       "  mean: 0.84039, std: 0.00866, params: {'subsample': 0.9, 'colsample_bytree': 0.7},\n",
       "  mean: 0.83894, std: 0.00921, params: {'subsample': 0.6, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83945, std: 0.00874, params: {'subsample': 0.7, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84055, std: 0.00855, params: {'subsample': 0.8, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84058, std: 0.00920, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83935, std: 0.00946, params: {'subsample': 0.6, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83972, std: 0.00923, params: {'subsample': 0.7, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83981, std: 0.00946, params: {'subsample': 0.8, 'colsample_bytree': 0.9},\n",
       "  mean: 0.83945, std: 0.00942, params: {'subsample': 0.9, 'colsample_bytree': 0.9}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       " 0.8405757633860711)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch4 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#0.05 intervals around these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.83946, std: 0.00911, params: {'subsample': 0.85, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83968, std: 0.00908, params: {'subsample': 0.9, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83971, std: 0.00937, params: {'subsample': 0.95, 'colsample_bytree': 0.75},\n",
       "  mean: 0.83972, std: 0.00886, params: {'subsample': 0.85, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84058, std: 0.00920, params: {'subsample': 0.9, 'colsample_bytree': 0.8},\n",
       "  mean: 0.84008, std: 0.00876, params: {'subsample': 0.95, 'colsample_bytree': 0.8},\n",
       "  mean: 0.83981, std: 0.00893, params: {'subsample': 0.85, 'colsample_bytree': 0.85},\n",
       "  mean: 0.84041, std: 0.00923, params: {'subsample': 0.9, 'colsample_bytree': 0.85},\n",
       "  mean: 0.84007, std: 0.00857, params: {'subsample': 0.95, 'colsample_bytree': 0.85}],\n",
       " {'colsample_bytree': 0.8, 'subsample': 0.9},\n",
       " 0.8405757633860711)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test5 = {\n",
    " 'subsample':[i/100.0 for i in range(85,100,5)],\n",
    " 'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "}\n",
    "gsearch5 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch5.fit(X_train,y_train)\n",
    "gsearch5.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.84058, std: 0.00920, params: {'reg_alpha': 1e-05},\n",
       "  mean: 0.84025, std: 0.00924, params: {'reg_alpha': 0.01},\n",
       "  mean: 0.83985, std: 0.00872, params: {'reg_alpha': 0.1},\n",
       "  mean: 0.84018, std: 0.00886, params: {'reg_alpha': 1},\n",
       "  mean: 0.82964, std: 0.00838, params: {'reg_alpha': 100}],\n",
       " {'reg_alpha': 1e-05},\n",
       " 0.84057580892653583)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test6 = {\n",
    " 'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "gsearch6 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=77, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.9, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test6, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch6.fit(X_train,y_train)\n",
    "gsearch6.grid_scores_, gsearch6.best_params_, gsearch6.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Step 6: Reducing Learning Rate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until cv error hasn't decreased in 50 rounds.\n",
      "[0]\tcv-test-auc:0.7668878+0.0447758819741\tcv-train-auc:0.7764546+0.0421354577979\n",
      "[1]\tcv-test-auc:0.8025282+0.0135798352479\tcv-train-auc:0.8141794+0.0045415561474\n",
      "[2]\tcv-test-auc:0.8078562+0.017067371636\tcv-train-auc:0.8198564+0.00740330335999\n",
      "[3]\tcv-test-auc:0.810158+0.0160780984323\tcv-train-auc:0.8219422+0.00840285323923\n",
      "[4]\tcv-test-auc:0.8127858+0.0134836377198\tcv-train-auc:0.8248904+0.00548050211568\n",
      "[5]\tcv-test-auc:0.8125252+0.0137919171459\tcv-train-auc:0.824738+0.00683081450487\n",
      "[6]\tcv-test-auc:0.815006+0.0118980251975\tcv-train-auc:0.8265252+0.00682582435754\n",
      "[7]\tcv-test-auc:0.8182028+0.0108325162063\tcv-train-auc:0.830798+0.00439759384209\n",
      "[8]\tcv-test-auc:0.8180468+0.0108898902364\tcv-train-auc:0.8313988+0.00342016230024\n",
      "[9]\tcv-test-auc:0.8190282+0.0104964543995\tcv-train-auc:0.8326366+0.00266678567568\n",
      "[10]\tcv-test-auc:0.8203448+0.00962782046779\tcv-train-auc:0.8340058+0.00222084338935\n",
      "[11]\tcv-test-auc:0.8215928+0.00928683449621\tcv-train-auc:0.8355502+0.00188635091115\n",
      "[12]\tcv-test-auc:0.8210096+0.0109442220665\tcv-train-auc:0.8352504+0.00228615945201\n",
      "[13]\tcv-test-auc:0.822265+0.0105155539654\tcv-train-auc:0.8364306+0.00192209995578\n",
      "[14]\tcv-test-auc:0.8230296+0.0101566405982\tcv-train-auc:0.8370028+0.00157028512061\n",
      "[15]\tcv-test-auc:0.824278+0.00919706931582\tcv-train-auc:0.8383424+0.00141064986442\n",
      "[16]\tcv-test-auc:0.8247328+0.0089949084798\tcv-train-auc:0.839051+0.000859715301713\n",
      "[17]\tcv-test-auc:0.8247472+0.00843086788889\tcv-train-auc:0.8392076+0.00160467437195\n",
      "[18]\tcv-test-auc:0.8251766+0.00811758187147\tcv-train-auc:0.8399894+0.00203957334754\n",
      "[19]\tcv-test-auc:0.825537+0.00842071001757\tcv-train-auc:0.8402968+0.00185558555718\n",
      "[20]\tcv-test-auc:0.8255988+0.00808849430735\tcv-train-auc:0.8405272+0.00268934508013\n",
      "[21]\tcv-test-auc:0.8255984+0.00808000414851\tcv-train-auc:0.8407294+0.00183641526894\n",
      "[22]\tcv-test-auc:0.8250102+0.00856304661671\tcv-train-auc:0.840329+0.00240710473391\n",
      "[23]\tcv-test-auc:0.8251702+0.00807713239708\tcv-train-auc:0.8405922+0.00183937765562\n",
      "[24]\tcv-test-auc:0.825982+0.00812481667485\tcv-train-auc:0.8414938+0.00183827064384\n",
      "[25]\tcv-test-auc:0.8258742+0.0075882697738\tcv-train-auc:0.8413002+0.00206751893824\n",
      "[26]\tcv-test-auc:0.825794+0.00735032034676\tcv-train-auc:0.841493+0.00172698488702\n",
      "[27]\tcv-test-auc:0.8259072+0.00689792137966\tcv-train-auc:0.8416272+0.00161086640042\n",
      "[28]\tcv-test-auc:0.826599+0.00679568415982\tcv-train-auc:0.8425568+0.00196521046201\n",
      "[29]\tcv-test-auc:0.8269578+0.00711623454925\tcv-train-auc:0.842897+0.00195386857286\n",
      "[30]\tcv-test-auc:0.827051+0.00701962597294\tcv-train-auc:0.8430008+0.00220383197182\n",
      "[31]\tcv-test-auc:0.8273608+0.00716984751302\tcv-train-auc:0.8433482+0.00217121895718\n",
      "[32]\tcv-test-auc:0.8278196+0.00705818547787\tcv-train-auc:0.844018+0.00224299371377\n",
      "[33]\tcv-test-auc:0.8279014+0.00689082652807\tcv-train-auc:0.8443656+0.00212207046066\n",
      "[34]\tcv-test-auc:0.82822+0.00690721767429\tcv-train-auc:0.8446582+0.00199595304554\n",
      "[35]\tcv-test-auc:0.8287162+0.00666729391583\tcv-train-auc:0.845274+0.00190047604563\n",
      "[36]\tcv-test-auc:0.828825+0.00730308425256\tcv-train-auc:0.8455412+0.00163985882319\n",
      "[37]\tcv-test-auc:0.8287456+0.00748169367456\tcv-train-auc:0.8458364+0.00132934519219\n",
      "[38]\tcv-test-auc:0.8290438+0.00738713179522\tcv-train-auc:0.8462674+0.00133521887344\n",
      "[39]\tcv-test-auc:0.8289586+0.00725696445079\tcv-train-auc:0.846301+0.00109746835945\n",
      "[40]\tcv-test-auc:0.8286822+0.00708434876047\tcv-train-auc:0.846234+0.0013621192312\n",
      "[41]\tcv-test-auc:0.8291262+0.00699770346328\tcv-train-auc:0.846666+0.00144514497543\n",
      "[42]\tcv-test-auc:0.82898+0.00686003198243\tcv-train-auc:0.8467726+0.00131878771605\n",
      "[43]\tcv-test-auc:0.829199+0.00678363374601\tcv-train-auc:0.8471804+0.00138699107423\n",
      "[44]\tcv-test-auc:0.8293126+0.00672695359282\tcv-train-auc:0.8475434+0.00122567999086\n",
      "[45]\tcv-test-auc:0.829688+0.00670387577451\tcv-train-auc:0.847897+0.00128176331669\n",
      "[46]\tcv-test-auc:0.8299354+0.0065393739945\tcv-train-auc:0.8479788+0.00125722828476\n",
      "[47]\tcv-test-auc:0.8298348+0.00617890143634\tcv-train-auc:0.8482468+0.00141025365094\n",
      "[48]\tcv-test-auc:0.8300872+0.00618205666102\tcv-train-auc:0.8486426+0.00144347741236\n",
      "[49]\tcv-test-auc:0.830176+0.00643902998906\tcv-train-auc:0.8487154+0.00136653687839\n",
      "[50]\tcv-test-auc:0.8302618+0.00653202689523\tcv-train-auc:0.8490604+0.00104671535768\n",
      "[51]\tcv-test-auc:0.8304318+0.00666224302769\tcv-train-auc:0.8492218+0.000837534094828\n",
      "[52]\tcv-test-auc:0.8304542+0.00684921173275\tcv-train-auc:0.8493466+0.000680869620412\n",
      "[53]\tcv-test-auc:0.8307784+0.00671331383446\tcv-train-auc:0.8496048+0.000786871628666\n",
      "[54]\tcv-test-auc:0.830956+0.0067409435838\tcv-train-auc:0.8498512+0.000953062306463\n",
      "[55]\tcv-test-auc:0.8309058+0.00654945553157\tcv-train-auc:0.8500822+0.00109177733994\n",
      "[56]\tcv-test-auc:0.8311484+0.00663360145321\tcv-train-auc:0.8504112+0.0011696661746\n",
      "[57]\tcv-test-auc:0.8310984+0.00648218483538\tcv-train-auc:0.8503888+0.00117665889705\n",
      "[58]\tcv-test-auc:0.8313658+0.0065920559585\tcv-train-auc:0.8507216+0.00130932174808\n",
      "[59]\tcv-test-auc:0.8314142+0.00669039148032\tcv-train-auc:0.850937+0.00133111502133\n",
      "[60]\tcv-test-auc:0.8316188+0.00672997377112\tcv-train-auc:0.8511934+0.00126718405924\n",
      "[61]\tcv-test-auc:0.8319146+0.00664085785422\tcv-train-auc:0.8515564+0.00117326290319\n",
      "[62]\tcv-test-auc:0.8321564+0.00673644477748\tcv-train-auc:0.8516934+0.00103458177057\n",
      "[63]\tcv-test-auc:0.8321686+0.00655529156026\tcv-train-auc:0.8519446+0.00103425230964\n",
      "[64]\tcv-test-auc:0.8322806+0.00640450271606\tcv-train-auc:0.8520896+0.00109540396202\n",
      "[65]\tcv-test-auc:0.8324406+0.00647337845642\tcv-train-auc:0.8523052+0.00108779692958\n",
      "[66]\tcv-test-auc:0.8327316+0.0065672387074\tcv-train-auc:0.8525606+0.0010535930144\n",
      "[67]\tcv-test-auc:0.833024+0.00659954174167\tcv-train-auc:0.8529172+0.000951165895099\n",
      "[68]\tcv-test-auc:0.8329816+0.00650420447403\tcv-train-auc:0.8530892+0.00106878742508\n",
      "[69]\tcv-test-auc:0.8332+0.0065046258309\tcv-train-auc:0.8533298+0.00105718974645\n",
      "[70]\tcv-test-auc:0.8332988+0.00660245031485\tcv-train-auc:0.853589+0.000960868357269\n",
      "[71]\tcv-test-auc:0.8335004+0.00677923720193\tcv-train-auc:0.8537994+0.000934297083373\n",
      "[72]\tcv-test-auc:0.8335456+0.00684234596027\tcv-train-auc:0.853939+0.000890926933031\n",
      "[73]\tcv-test-auc:0.8336382+0.00680948933181\tcv-train-auc:0.8541452+0.000827966762618\n",
      "[74]\tcv-test-auc:0.833732+0.0069127720055\tcv-train-auc:0.8543444+0.000785933992139\n",
      "[75]\tcv-test-auc:0.8338062+0.00681902155445\tcv-train-auc:0.8546164+0.000774224928558\n",
      "[76]\tcv-test-auc:0.8337146+0.00674539975391\tcv-train-auc:0.8547242+0.000817289520305\n",
      "[77]\tcv-test-auc:0.8340074+0.00658726224163\tcv-train-auc:0.8548512+0.000857797971553\n",
      "[78]\tcv-test-auc:0.8340998+0.00656325901972\tcv-train-auc:0.8550554+0.000870355008028\n",
      "[79]\tcv-test-auc:0.8342522+0.00659358474276\tcv-train-auc:0.8552518+0.000840579895072\n",
      "[80]\tcv-test-auc:0.8342342+0.00657848150868\tcv-train-auc:0.8554316+0.000886878480966\n",
      "[81]\tcv-test-auc:0.8344164+0.00656194369375\tcv-train-auc:0.8556462+0.000881238537514\n",
      "[82]\tcv-test-auc:0.8345736+0.0064459485136\tcv-train-auc:0.8558314+0.000928999160387\n",
      "[83]\tcv-test-auc:0.8347424+0.00660605227348\tcv-train-auc:0.8560188+0.000863538395209\n",
      "[84]\tcv-test-auc:0.8348574+0.00659806315823\tcv-train-auc:0.8561812+0.000862621446522\n",
      "[85]\tcv-test-auc:0.835002+0.0066382881227\tcv-train-auc:0.8563944+0.000806745709626\n",
      "[86]\tcv-test-auc:0.8351074+0.00654955548415\tcv-train-auc:0.856471+0.000839080687419\n",
      "[87]\tcv-test-auc:0.8351056+0.00645453361909\tcv-train-auc:0.8566644+0.000771552616482\n",
      "[88]\tcv-test-auc:0.835145+0.00655272264025\tcv-train-auc:0.8567712+0.000771552564638\n",
      "[89]\tcv-test-auc:0.8351844+0.00648487756554\tcv-train-auc:0.85701+0.000758037466093\n",
      "[90]\tcv-test-auc:0.8352042+0.00639294844027\tcv-train-auc:0.857151+0.000691059476456\n",
      "[91]\tcv-test-auc:0.835347+0.00631115732651\tcv-train-auc:0.857434+0.000650839457931\n",
      "[92]\tcv-test-auc:0.835475+0.00634811688613\tcv-train-auc:0.8576114+0.000663721809194\n",
      "[93]\tcv-test-auc:0.8355614+0.00636180039297\tcv-train-auc:0.8578296+0.000697430025164\n",
      "[94]\tcv-test-auc:0.8355698+0.00642730000545\tcv-train-auc:0.8580366+0.000658105341112\n",
      "[95]\tcv-test-auc:0.8357172+0.00635179531786\tcv-train-auc:0.8582384+0.00066742448262\n",
      "[96]\tcv-test-auc:0.8356908+0.00632426170869\tcv-train-auc:0.8583984+0.000606580777803\n",
      "[97]\tcv-test-auc:0.8358622+0.00634147760069\tcv-train-auc:0.8586222+0.000559690057085\n",
      "[98]\tcv-test-auc:0.8358554+0.0062264942817\tcv-train-auc:0.8587814+0.00063798545438\n",
      "[99]\tcv-test-auc:0.8359836+0.00625867032524\tcv-train-auc:0.8589912+0.000723674899385\n",
      "[100]\tcv-test-auc:0.8360654+0.00631466108671\tcv-train-auc:0.8592544+0.000685511371168\n",
      "[101]\tcv-test-auc:0.8360716+0.00624929773975\tcv-train-auc:0.8595318+0.000592519164247\n",
      "[102]\tcv-test-auc:0.8361552+0.0062852249729\tcv-train-auc:0.859774+0.000554713259261\n",
      "[103]\tcv-test-auc:0.8362658+0.0061961526579\tcv-train-auc:0.8600238+0.000563986666509\n",
      "[104]\tcv-test-auc:0.8363184+0.00621280737187\tcv-train-auc:0.8601652+0.000567125171369\n",
      "[105]\tcv-test-auc:0.8364526+0.00621025302544\tcv-train-auc:0.8603594+0.000609531164093\n",
      "[106]\tcv-test-auc:0.8366136+0.00621030555126\tcv-train-auc:0.8605902+0.000601425772644\n",
      "[107]\tcv-test-auc:0.8366572+0.00615760782772\tcv-train-auc:0.8606868+0.00058445509665\n",
      "[108]\tcv-test-auc:0.8366908+0.00609505843778\tcv-train-auc:0.8609068+0.000558896555724\n",
      "[109]\tcv-test-auc:0.8366932+0.00599051969031\tcv-train-auc:0.8611542+0.000557162238491\n",
      "[110]\tcv-test-auc:0.8367652+0.00598256230724\tcv-train-auc:0.8613972+0.000606025544016\n",
      "[111]\tcv-test-auc:0.8368082+0.00589799591048\tcv-train-auc:0.8616262+0.000629866462038\n",
      "[112]\tcv-test-auc:0.8368764+0.00589124491428\tcv-train-auc:0.8617688+0.000600547883187\n",
      "[113]\tcv-test-auc:0.8369054+0.00586414551661\tcv-train-auc:0.861936+0.000553887353168\n",
      "[114]\tcv-test-auc:0.8369+0.00589095330146\tcv-train-auc:0.8621272+0.00052792931345\n",
      "[115]\tcv-test-auc:0.836946+0.00584575986506\tcv-train-auc:0.8622814+0.000510932324286\n",
      "[116]\tcv-test-auc:0.8370262+0.00579698961186\tcv-train-auc:0.8624398+0.000493254254923\n",
      "[117]\tcv-test-auc:0.8371644+0.00576215347244\tcv-train-auc:0.8626142+0.000519234205345\n",
      "[118]\tcv-test-auc:0.8372838+0.00572768446757\tcv-train-auc:0.8628442+0.000439768302632\n",
      "[119]\tcv-test-auc:0.8374216+0.00566712797103\tcv-train-auc:0.8630104+0.000440070721589\n",
      "[120]\tcv-test-auc:0.837517+0.00570364634247\tcv-train-auc:0.8632054+0.000456238797123\n",
      "[121]\tcv-test-auc:0.8375292+0.00570683328651\tcv-train-auc:0.8633838+0.000474499483667\n",
      "[122]\tcv-test-auc:0.8375868+0.0057491951228\tcv-train-auc:0.863565+0.000456717418104\n",
      "[123]\tcv-test-auc:0.8376894+0.00571376672958\tcv-train-auc:0.8637218+0.000493307774113\n",
      "[124]\tcv-test-auc:0.8376976+0.00562705822255\tcv-train-auc:0.8638924+0.000492484964237\n",
      "[125]\tcv-test-auc:0.837759+0.00565724314485\tcv-train-auc:0.8640882+0.000488013688333\n",
      "[126]\tcv-test-auc:0.8378434+0.00567124362376\tcv-train-auc:0.864236+0.000520316057796\n",
      "[127]\tcv-test-auc:0.8378988+0.00561416014734\tcv-train-auc:0.8644346+0.000484284461861\n",
      "[128]\tcv-test-auc:0.8379508+0.00561465323595\tcv-train-auc:0.8646172+0.000525450815967\n",
      "[129]\tcv-test-auc:0.8379658+0.00563367359367\tcv-train-auc:0.864821+0.000506899990136\n",
      "[130]\tcv-test-auc:0.8380076+0.00556157501433\tcv-train-auc:0.864993+0.000473736635695\n",
      "[131]\tcv-test-auc:0.8381016+0.00566723042058\tcv-train-auc:0.8651408+0.000445996591915\n",
      "[132]\tcv-test-auc:0.8381432+0.00566327224844\tcv-train-auc:0.8653576+0.00042340741609\n",
      "[133]\tcv-test-auc:0.8382412+0.0056589153519\tcv-train-auc:0.8655162+0.000433258537135\n",
      "[134]\tcv-test-auc:0.8383614+0.00560782680189\tcv-train-auc:0.8657054+0.000475527748927\n",
      "[135]\tcv-test-auc:0.838361+0.00566203027191\tcv-train-auc:0.8658448+0.000498277994698\n",
      "[136]\tcv-test-auc:0.8384026+0.00566069481954\tcv-train-auc:0.8660266+0.000545208804037\n",
      "[137]\tcv-test-auc:0.8384464+0.00564512014398\tcv-train-auc:0.8661792+0.000533202925723\n",
      "[138]\tcv-test-auc:0.8384818+0.00564503468191\tcv-train-auc:0.8663406+0.000547448116263\n",
      "[139]\tcv-test-auc:0.8385724+0.0055465687267\tcv-train-auc:0.8664952+0.00051823060504\n",
      "[140]\tcv-test-auc:0.8385996+0.00555249229085\tcv-train-auc:0.866626+0.000509434195947\n",
      "[141]\tcv-test-auc:0.8387262+0.00552103593178\tcv-train-auc:0.8667712+0.000514792540739\n",
      "[142]\tcv-test-auc:0.838693+0.00548392228245\tcv-train-auc:0.8669168+0.000520927403771\n",
      "[143]\tcv-test-auc:0.8386812+0.00545074752305\tcv-train-auc:0.8670686+0.000538326518017\n",
      "[144]\tcv-test-auc:0.8386998+0.00542507409719\tcv-train-auc:0.8672452+0.000522230370622\n",
      "[145]\tcv-test-auc:0.8387104+0.00542143252656\tcv-train-auc:0.8674012+0.000545318402404\n",
      "[146]\tcv-test-auc:0.8387728+0.00544661492672\tcv-train-auc:0.8675662+0.000537563912479\n",
      "[147]\tcv-test-auc:0.8388596+0.00541003795181\tcv-train-auc:0.8677088+0.000566833097128\n",
      "[148]\tcv-test-auc:0.8389152+0.00536672713672\tcv-train-auc:0.8678906+0.000551281271222\n",
      "[149]\tcv-test-auc:0.8389304+0.0053382775724\tcv-train-auc:0.8680546+0.000546545368657\n",
      "[150]\tcv-test-auc:0.8389506+0.00530545020144\tcv-train-auc:0.868205+0.00053029840656\n",
      "[151]\tcv-test-auc:0.8390296+0.00526916424493\tcv-train-auc:0.8683606+0.000510928018414\n",
      "[152]\tcv-test-auc:0.8390048+0.00526113373333\tcv-train-auc:0.8685102+0.000513104823598\n",
      "[153]\tcv-test-auc:0.839112+0.00522247607941\tcv-train-auc:0.8686398+0.000493605267395\n",
      "[154]\tcv-test-auc:0.839162+0.00520136197548\tcv-train-auc:0.868784+0.000480400666111\n",
      "[155]\tcv-test-auc:0.8391522+0.00522655417651\tcv-train-auc:0.8689754+0.000534269070787\n",
      "[156]\tcv-test-auc:0.8391916+0.0052280079801\tcv-train-auc:0.8690916+0.0005259831176\n",
      "[157]\tcv-test-auc:0.8392854+0.00517776328544\tcv-train-auc:0.8692324+0.000522485827559\n",
      "[158]\tcv-test-auc:0.8393502+0.00516306542279\tcv-train-auc:0.8693694+0.000551743273634\n",
      "[159]\tcv-test-auc:0.839353+0.00509862997285\tcv-train-auc:0.8695232+0.000546134562173\n",
      "[160]\tcv-test-auc:0.8393906+0.00511630169556\tcv-train-auc:0.8696616+0.000530851617686\n",
      "[161]\tcv-test-auc:0.8394186+0.00513033763411\tcv-train-auc:0.8697712+0.000549870675705\n",
      "[162]\tcv-test-auc:0.839399+0.00514698253349\tcv-train-auc:0.8699432+0.000520534110314\n",
      "[163]\tcv-test-auc:0.8394482+0.00509552797657\tcv-train-auc:0.8700716+0.000528231994487\n",
      "[164]\tcv-test-auc:0.839495+0.00510326769825\tcv-train-auc:0.8702106+0.000539790551974\n",
      "[165]\tcv-test-auc:0.839529+0.00509312069364\tcv-train-auc:0.8703286+0.000544419544102\n",
      "[166]\tcv-test-auc:0.8395506+0.00511380017599\tcv-train-auc:0.8704588+0.000550580929564\n",
      "[167]\tcv-test-auc:0.839551+0.00511258983295\tcv-train-auc:0.8705928+0.000489008547983\n",
      "[168]\tcv-test-auc:0.8395656+0.00504581773749\tcv-train-auc:0.8707358+0.00051449019427\n",
      "[169]\tcv-test-auc:0.839549+0.00504232144949\tcv-train-auc:0.870859+0.000521412696432\n",
      "[170]\tcv-test-auc:0.839522+0.00505057481877\tcv-train-auc:0.8709686+0.000510195099937\n",
      "[171]\tcv-test-auc:0.83959+0.00504255538393\tcv-train-auc:0.8711014+0.00050677908402\n",
      "[172]\tcv-test-auc:0.8395732+0.00500979813565\tcv-train-auc:0.871237+0.000493635898208\n",
      "[173]\tcv-test-auc:0.8395946+0.00501243296614\tcv-train-auc:0.8713652+0.000500941274003\n",
      "[174]\tcv-test-auc:0.839594+0.00504940309344\tcv-train-auc:0.871519+0.000522895018144\n",
      "[175]\tcv-test-auc:0.8395888+0.00505477043593\tcv-train-auc:0.8716728+0.000508853377703\n",
      "[176]\tcv-test-auc:0.8396088+0.00498291297937\tcv-train-auc:0.871805+0.00047664368243\n",
      "[177]\tcv-test-auc:0.8396806+0.00493593563977\tcv-train-auc:0.8719388+0.000510388244379\n",
      "[178]\tcv-test-auc:0.839699+0.00489483176422\tcv-train-auc:0.872077+0.000520476320307\n",
      "[179]\tcv-test-auc:0.8397432+0.00489534118934\tcv-train-auc:0.8721756+0.000540260529745\n",
      "[180]\tcv-test-auc:0.8397624+0.00486143742529\tcv-train-auc:0.8723008+0.000546119913572\n",
      "[181]\tcv-test-auc:0.8397952+0.00487705572656\tcv-train-auc:0.8724516+0.00061625858209\n",
      "[182]\tcv-test-auc:0.8398402+0.0048870767295\tcv-train-auc:0.8725904+0.000640200156201\n",
      "[183]\tcv-test-auc:0.8398366+0.00487086582037\tcv-train-auc:0.8727744+0.000655086742348\n",
      "[184]\tcv-test-auc:0.8398726+0.00488092993599\tcv-train-auc:0.8728788+0.000674488665583\n",
      "[185]\tcv-test-auc:0.839874+0.00488200823432\tcv-train-auc:0.8730082+0.000694180207151\n",
      "[186]\tcv-test-auc:0.8398532+0.00486699128415\tcv-train-auc:0.8731428+0.000681160304187\n",
      "[187]\tcv-test-auc:0.8398594+0.00488742179886\tcv-train-auc:0.873262+0.000719690211133\n",
      "[188]\tcv-test-auc:0.8398732+0.00490302353247\tcv-train-auc:0.8734054+0.000684079702959\n",
      "[189]\tcv-test-auc:0.839879+0.00486111168356\tcv-train-auc:0.8735122+0.000654640786997\n",
      "[190]\tcv-test-auc:0.8397826+0.00487343002822\tcv-train-auc:0.8736206+0.000657948204648\n",
      "[191]\tcv-test-auc:0.839877+0.00485439038397\tcv-train-auc:0.8737752+0.00067453077024\n",
      "[192]\tcv-test-auc:0.8398756+0.00486121978931\tcv-train-auc:0.873921+0.000625374128023\n",
      "[193]\tcv-test-auc:0.8398668+0.00484854433413\tcv-train-auc:0.8740308+0.000609869953351\n",
      "[194]\tcv-test-auc:0.8398782+0.00484257288639\tcv-train-auc:0.8741616+0.00060285407853\n",
      "[195]\tcv-test-auc:0.8398856+0.00483900112007\tcv-train-auc:0.8742462+0.000602418260015\n",
      "[196]\tcv-test-auc:0.8398854+0.00483818795005\tcv-train-auc:0.8743816+0.000541658785584\n",
      "[197]\tcv-test-auc:0.8398946+0.00484343781213\tcv-train-auc:0.8745122+0.000521245968809\n",
      "[198]\tcv-test-auc:0.8398832+0.00484022790373\tcv-train-auc:0.8746548+0.0005378506856\n",
      "[199]\tcv-test-auc:0.839904+0.00482468535762\tcv-train-auc:0.8747388+0.000524258485864\n",
      "[200]\tcv-test-auc:0.839903+0.00479448912816\tcv-train-auc:0.8748758+0.000505950748591\n",
      "[201]\tcv-test-auc:0.8399102+0.00479170397249\tcv-train-auc:0.8749946+0.000513134134511\n",
      "[202]\tcv-test-auc:0.8399484+0.00477072454036\tcv-train-auc:0.875107+0.000499687902595\n",
      "[203]\tcv-test-auc:0.8399746+0.00476566564501\tcv-train-auc:0.8752014+0.000490241817882\n",
      "[204]\tcv-test-auc:0.83998+0.00478462775982\tcv-train-auc:0.8753278+0.000467462683003\n",
      "[205]\tcv-test-auc:0.8400174+0.00475910590763\tcv-train-auc:0.8754608+0.000485229182964\n",
      "[206]\tcv-test-auc:0.8400412+0.00477998453554\tcv-train-auc:0.8755388+0.000499217547769\n",
      "[207]\tcv-test-auc:0.8400646+0.0047835419764\tcv-train-auc:0.8756172+0.000515848194724\n",
      "[208]\tcv-test-auc:0.8400576+0.00477693816581\tcv-train-auc:0.8757092+0.000551459300402\n",
      "[209]\tcv-test-auc:0.8400428+0.00479748277329\tcv-train-auc:0.8758432+0.000559882987775\n",
      "[210]\tcv-test-auc:0.8400382+0.00485810281489\tcv-train-auc:0.8759544+0.00054659989023\n",
      "[211]\tcv-test-auc:0.8400122+0.00490919917706\tcv-train-auc:0.876016+0.000548001824814\n",
      "[212]\tcv-test-auc:0.8399686+0.00492424802787\tcv-train-auc:0.8760898+0.000544856458161\n",
      "[213]\tcv-test-auc:0.8398832+0.00494890074259\tcv-train-auc:0.8762266+0.000575083854755\n",
      "[214]\tcv-test-auc:0.8398592+0.00492220525375\tcv-train-auc:0.8763188+0.000577208246649\n",
      "[215]\tcv-test-auc:0.8398762+0.00493567079129\tcv-train-auc:0.8764596+0.000548529160574\n",
      "[216]\tcv-test-auc:0.8398484+0.00495731752463\tcv-train-auc:0.8765576+0.000556075390572\n",
      "[217]\tcv-test-auc:0.8398604+0.0049490384359\tcv-train-auc:0.876691+0.000542374409426\n",
      "[218]\tcv-test-auc:0.8398746+0.00494593835789\tcv-train-auc:0.8768006+0.000518077445948\n",
      "[219]\tcv-test-auc:0.8398888+0.00496007449138\tcv-train-auc:0.8769008+0.000543365585955\n",
      "[220]\tcv-test-auc:0.8398908+0.00498444979511\tcv-train-auc:0.877005+0.000538883289776\n",
      "[221]\tcv-test-auc:0.8398924+0.00501159665576\tcv-train-auc:0.8771+0.000524431501724\n",
      "[222]\tcv-test-auc:0.8399056+0.00501351599579\tcv-train-auc:0.8771896+0.000555257994089\n",
      "[223]\tcv-test-auc:0.8398534+0.00501551343733\tcv-train-auc:0.8772746+0.000525712697203\n",
      "[224]\tcv-test-auc:0.8398118+0.00501880142664\tcv-train-auc:0.8773474+0.000521522616959\n",
      "[225]\tcv-test-auc:0.8397694+0.00500609686682\tcv-train-auc:0.8774692+0.000491285416026\n",
      "[226]\tcv-test-auc:0.8397748+0.00499387522471\tcv-train-auc:0.8775544+0.00046308901952\n",
      "[227]\tcv-test-auc:0.8397232+0.00497857985373\tcv-train-auc:0.8777218+0.000450787932403\n",
      "[228]\tcv-test-auc:0.8397052+0.00496232902577\tcv-train-auc:0.8778362+0.000490301295124\n",
      "[229]\tcv-test-auc:0.839714+0.00496552502763\tcv-train-auc:0.8779364+0.000523441152375\n",
      "[230]\tcv-test-auc:0.8397468+0.00494663576181\tcv-train-auc:0.878066+0.000468719532343\n",
      "[231]\tcv-test-auc:0.8397586+0.00491215954953\tcv-train-auc:0.878176+0.000409886325705\n",
      "[232]\tcv-test-auc:0.8397816+0.00492860692691\tcv-train-auc:0.8782814+0.000418013683987\n",
      "[233]\tcv-test-auc:0.8397924+0.00491225327523\tcv-train-auc:0.8783568+0.000440477195777\n",
      "[234]\tcv-test-auc:0.8397766+0.00488611881149\tcv-train-auc:0.8784316+0.000438319791933\n",
      "[235]\tcv-test-auc:0.8397654+0.00489176600422\tcv-train-auc:0.8785294+0.000423704425278\n",
      "[236]\tcv-test-auc:0.8397792+0.00488504621882\tcv-train-auc:0.8786438+0.000419002338896\n",
      "[237]\tcv-test-auc:0.8397882+0.00488769996624\tcv-train-auc:0.8787616+0.000397269983764\n",
      "[238]\tcv-test-auc:0.8397886+0.00490912124927\tcv-train-auc:0.878866+0.00038535645836\n",
      "[239]\tcv-test-auc:0.8398076+0.00488985147423\tcv-train-auc:0.8789728+0.00039599969697\n",
      "[240]\tcv-test-auc:0.8398096+0.00489677194078\tcv-train-auc:0.8790542+0.000406037141158\n",
      "[241]\tcv-test-auc:0.839829+0.00487070376845\tcv-train-auc:0.8791202+0.000386536104394\n",
      "[242]\tcv-test-auc:0.8398078+0.00486359638128\tcv-train-auc:0.8792614+0.000395918981611\n",
      "[243]\tcv-test-auc:0.8397986+0.00487574431651\tcv-train-auc:0.879354+0.000376433261017\n",
      "[244]\tcv-test-auc:0.8397956+0.00487361166282\tcv-train-auc:0.879461+0.000358626825544\n",
      "[245]\tcv-test-auc:0.839783+0.00490243119279\tcv-train-auc:0.8795548+0.000335816259285\n",
      "[246]\tcv-test-auc:0.8397324+0.00491890189372\tcv-train-auc:0.8796582+0.000354379119024\n",
      "[247]\tcv-test-auc:0.8397452+0.0049086995182\tcv-train-auc:0.8796982+0.000353886083366\n",
      "[248]\tcv-test-auc:0.8397432+0.0048918605622\tcv-train-auc:0.8798276+0.000383832046604\n",
      "[249]\tcv-test-auc:0.839743+0.00486421825168\tcv-train-auc:0.8799106+0.000392061525784\n",
      "[250]\tcv-test-auc:0.8397396+0.00484919480326\tcv-train-auc:0.8799666+0.000368871576568\n",
      "[251]\tcv-test-auc:0.8397454+0.0048661179846\tcv-train-auc:0.8800742+0.000407070215073\n",
      "[252]\tcv-test-auc:0.839751+0.00483937247998\tcv-train-auc:0.880179+0.000407456991595\n",
      "[253]\tcv-test-auc:0.8397522+0.00485225627518\tcv-train-auc:0.8802756+0.000402473154384\n",
      "[254]\tcv-test-auc:0.8397708+0.0048629206615\tcv-train-auc:0.8803812+0.000425973426401\n",
      "[255]\tcv-test-auc:0.8397738+0.00483409190645\tcv-train-auc:0.8804782+0.000402460631615\n",
      "[256]\tcv-test-auc:0.839741+0.00488759593256\tcv-train-auc:0.8805854+0.00037568529383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0         0.766888      0.044776        0.776455       0.042135\n",
      "1         0.802528      0.013580        0.814179       0.004542\n",
      "2         0.807856      0.017067        0.819856       0.007403\n",
      "3         0.810158      0.016078        0.821942       0.008403\n",
      "4         0.812786      0.013484        0.824890       0.005481\n",
      "5         0.812525      0.013792        0.824738       0.006831\n",
      "6         0.815006      0.011898        0.826525       0.006826\n",
      "7         0.818203      0.010833        0.830798       0.004398\n",
      "8         0.818047      0.010890        0.831399       0.003420\n",
      "9         0.819028      0.010496        0.832637       0.002667\n",
      "10        0.820345      0.009628        0.834006       0.002221\n",
      "11        0.821593      0.009287        0.835550       0.001886\n",
      "12        0.821010      0.010944        0.835250       0.002286\n",
      "13        0.822265      0.010516        0.836431       0.001922\n",
      "14        0.823030      0.010157        0.837003       0.001570\n",
      "15        0.824278      0.009197        0.838342       0.001411\n",
      "16        0.824733      0.008995        0.839051       0.000860\n",
      "17        0.824747      0.008431        0.839208       0.001605\n",
      "18        0.825177      0.008118        0.839989       0.002040\n",
      "19        0.825537      0.008421        0.840297       0.001856\n",
      "20        0.825599      0.008088        0.840527       0.002689\n",
      "21        0.825598      0.008080        0.840729       0.001836\n",
      "22        0.825010      0.008563        0.840329       0.002407\n",
      "23        0.825170      0.008077        0.840592       0.001839\n",
      "24        0.825982      0.008125        0.841494       0.001838\n",
      "25        0.825874      0.007588        0.841300       0.002068\n",
      "26        0.825794      0.007350        0.841493       0.001727\n",
      "27        0.825907      0.006898        0.841627       0.001611\n",
      "28        0.826599      0.006796        0.842557       0.001965\n",
      "29        0.826958      0.007116        0.842897       0.001954\n",
      "..             ...           ...             ...            ...\n",
      "178       0.839699      0.004895        0.872077       0.000520\n",
      "179       0.839743      0.004895        0.872176       0.000540\n",
      "180       0.839762      0.004861        0.872301       0.000546\n",
      "181       0.839795      0.004877        0.872452       0.000616\n",
      "182       0.839840      0.004887        0.872590       0.000640\n",
      "183       0.839837      0.004871        0.872774       0.000655\n",
      "184       0.839873      0.004881        0.872879       0.000674\n",
      "185       0.839874      0.004882        0.873008       0.000694\n",
      "186       0.839853      0.004867        0.873143       0.000681\n",
      "187       0.839859      0.004887        0.873262       0.000720\n",
      "188       0.839873      0.004903        0.873405       0.000684\n",
      "189       0.839879      0.004861        0.873512       0.000655\n",
      "190       0.839783      0.004873        0.873621       0.000658\n",
      "191       0.839877      0.004854        0.873775       0.000675\n",
      "192       0.839876      0.004861        0.873921       0.000625\n",
      "193       0.839867      0.004849        0.874031       0.000610\n",
      "194       0.839878      0.004843        0.874162       0.000603\n",
      "195       0.839886      0.004839        0.874246       0.000602\n",
      "196       0.839885      0.004838        0.874382       0.000542\n",
      "197       0.839895      0.004843        0.874512       0.000521\n",
      "198       0.839883      0.004840        0.874655       0.000538\n",
      "199       0.839904      0.004825        0.874739       0.000524\n",
      "200       0.839903      0.004794        0.874876       0.000506\n",
      "201       0.839910      0.004792        0.874995       0.000513\n",
      "202       0.839948      0.004771        0.875107       0.000500\n",
      "203       0.839975      0.004766        0.875201       0.000490\n",
      "204       0.839980      0.004785        0.875328       0.000467\n",
      "205       0.840017      0.004759        0.875461       0.000485\n",
      "206       0.840041      0.004780        0.875539       0.000499\n",
      "207       0.840065      0.004784        0.875617       0.000516\n",
      "\n",
      "[208 rows x 4 columns]\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9608\n",
      "AUC Score (Train): 0.869309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[257]\tcv-test-auc:0.8397236+0.00490025805851\tcv-train-auc:0.8806558+0.00038889967858\n",
      "Stopping. Best iteration: 207\n"
     ]
    }
   ],
   "source": [
    "xgb3 = XGBClassifier(missing=np.nan,\n",
    " learning_rate =0.03,\n",
    " n_estimators=10000,\n",
    " max_depth=5,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.9,\n",
    " colsample_bytree=0.8,\n",
    " reg_alpha=1e-05,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " seed=27)\n",
    "modelfit(xgb3, X_train, y_train,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall AUC:', 0.86930937094208349)\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "print('Overall AUC:', roc_auc_score(y_train, xgb3.predict_proba(X_train)[:,1]))\n",
    "\n",
    "# predicting\n",
    "y_pred= xgb3.predict_proba(X_test)[:,1]\n",
    "\n",
    "submission = pd.DataFrame({\"ID\":id_test, \"TARGET\":y_pred})\n",
    "submission.to_csv(\"submission_xgb.csv\", index=False)\n",
    "\n",
    "print('Completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
